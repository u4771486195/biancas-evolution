phase_id: 19
name: The Metropolis
goal: >
  Planet-Scale AI, Federated Learning, Zero-Trust Mesh, Sovereign Data
  Resilience. FINAL STATE: Active-Active Multi-Region (EU/US/Asia) with
  1,000,000+ workers/robots. OPERATIONAL POSTURE: 0-RPO global ledger, telemetry
  firehose isolation, headless edge autonomy on K3s. DATA GRAVITY (ENFORCED):
  Raw telemetry + PII NEVER leave their origin region (GDPR/local labor law).
  Cross-region replication is LIMITED to:
    (a) anonymized aggregates,
    (b) signed federated weight/gradient deltas,
    (c) globally-consensused hashes + attestations.
  ACTUATION BOUNDARY (NON-NEGOTIABLE): All state transitions happen via Temporal
  Workflows. AI trainers are read-only; they never write to databases directly.
stack: >-
  Kubernetes (Federated), CockroachDB (Global), ScyllaDB (Telemetry), Rust +
  Python (AI), Temporal, Federated Kafka, Linkerd
phase_overlays:
  - name: bootstrap
    phases:
      - 1
      - 2
      - 3
      - 4
      - 5
      - 6
    description: >
      Single-region, non-Kubernetes footprint focused on proving the model and
      freeing the CEO. Minimal always-on infra, no Kafka, no federation.
    enabled_components:
      - services/core-engine/work-orders
      - services/core-engine/hr-registry
      - database/migrations/cockroach/
      - platform/backstage/templates/python-service/template.yaml
    disabled_components:
      - infrastructure/k8s/federation/
      - infrastructure/kafka/federation/
      - services/ai-player/
      - services/simulation-engine/
      constraints:
        max_regions: 1
        requires_temporal: false
        ledger_rpo: "<= 5m"
        telemetry_retention: 7d
        ai_scope: recommendation experiments only
        
  - name: expansion
    phases:
      - 7
      - 8
      - 9
      - 10
      - 11
      - 12
    description: >
      Multi-city + multi-country but single-cloud, Kubernetes-based,
      event-driven with Digital Twin v1 + Observability.
    enabled_components:
      - infrastructure/k8s/federation/control-plane/
      - infrastructure/k8s/federation/clusters/
      - infrastructure/kafka/regions/
      - services/temporal-workers/dispatch/
      - services/simulation-engine/
      - observability/prometheus/
      - observability/grafana/dashboards/
    disabled_components:
      - infrastructure/kafka/federation/
      - services/ai-governor/
    constraints:
      max_regions: 3
      requires_temporal: true
      ledger_rpo: '0'
      telemetry_retention: 30d
      ai_scope: per-region optimizations; no federated learning
  - name: metropolis
    phases:
      - 13
      - 14
      - 15
      - 16
      - 17
      - 18
      - 19
    description: >
      Federated multi-cloud, multi-region deployment with sovereign data,
      federated Kafka, federated learning and service mesh everywhere.
    enabled_components:
      - infrastructure/kafka/federation/
      - platform/charts/linkerd/
      - platform/charts/cockroachdb/
      - platform/charts/scylladb/
      - services/ai-player/
      - services/ai-governor/
      - platform/policy/opa/
      - platform/policy/cedar/
      - observability/prometheus/slos/
      - runbooks/
      - ci/pipelines/
    disabled_components: []
    constraints:
      max_regions: 9
      requires_temporal: true
      ledger_rpo: '0'
      telemetry_retention: 365d
      ai_scope: planet-scale federated learning under strict governance

phases:
  '1':
    name: Prove the Model
    overlay: bootstrap
    workers_range: "1"
    roadmap_ref: Phase 1 ‚Äì Prove the Model
    primary_goal: MVP + zero recurring infra cost.
    infra_profile:
      uses_kubernetes: false
      uses_kafka: false
      uses_temporal: false
  '2':
    name: Free the CEO
    overlay: bootstrap
    workers_range: "2"
    roadmap_ref: Phase 2 ‚Äì Free the CEO
    primary_goal: Reliability + always-on DB.
    infra_profile:
      uses_kubernetes: false
      uses_kafka: false
      uses_temporal: false
  '3':
    name: Systematize Scheduling
    overlay: bootstrap
    workers_range: "3-5"
    roadmap_ref: Phase 3 ‚Äì Systematize Scheduling
    primary_goal: Internal tools + basic worker app.
    infra_profile:
      uses_kubernetes: false
      uses_kafka: false
      uses_temporal: false
  '4':
    name: Automate Finance
    overlay: bootstrap
    workers_range: "6-10"
    roadmap_ref: Phase 4 ‚Äì Automate Finance
    primary_goal: Finance engine + error-free invoicing/payroll.
    infra_profile:
      uses_kubernetes: false
      uses_kafka: false
      uses_temporal: false
  '5':
    name: Optimize Routing
    overlay: bootstrap
    workers_range: "11-25"
    roadmap_ref: Phase 5 ‚Äì Optimize Routing
    primary_goal: OSRM/Valhalla-based routing cost reduction.
    infra_profile:
      uses_kubernetes: false
      uses_kafka: false
      uses_temporal: false
  '6':
    name: Improve Performance
    overlay: bootstrap
    workers_range: "26-50"
    roadmap_ref: Phase 6 ‚Äì Improve Performance
    primary_goal: Introduce Temporal for durable workflows.
    infra_profile:
      uses_kubernetes: false
      uses_kafka: false
      uses_temporal: true
  '7':
    name: Multi-City Expansion
    overlay: expansion
    workers_range: "51-100"
    roadmap_ref: Phase 7 ‚Äì Prepare for Multi-City Expansion
    primary_goal: Sovereign identity + first microservice.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: false
      uses_temporal: true
  '8':
    name: Kubernetes Migration
    overlay: expansion
    workers_range: "101-250"
    roadmap_ref: Phase 8 ‚Äì Kubernetes Migration
    primary_goal: Full K8s migration + IaC baseline.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: false
      uses_temporal: true
  '9':
    name: Event-Driven Architecture
    overlay: expansion
    workers_range: "251-500"
    roadmap_ref: Phase 9 ‚Äì Event-Driven Architecture
    primary_goal: Kafka nervous system; events over RPC.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: true
      uses_temporal: true
  '10':
    name: '"Digital Twin" v1'
    overlay: expansion
    workers_range: "501-1,000"
    roadmap_ref: Phase 10 ‚Äì Digital Twin v1
    primary_goal: Real-time operational twin.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: true
      uses_temporal: true
  '11':
    name: True Observability
    overlay: expansion
    workers_range: "1,001-2,500"
    roadmap_ref: Phase 11 ‚Äì True Observability
    primary_goal: SLO-driven operations.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: true
      uses_temporal: true
  '12':
    name: Data-Driven Intelligence
    overlay: expansion
    workers_range: "2,501-5,000"
    roadmap_ref: Phase 12 ‚Äì Data-Driven Intelligence
    primary_goal: Lakehouse + AI-CEO v1.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: true
      uses_temporal: true
  '13':
    name: Multi-Region Expansion
    overlay: metropolis
    workers_range: "5,001-10,000"
    roadmap_ref: Phase 13 ‚Äì Multi-Region Expansion
    primary_goal: Anycast + multi-region K8s.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: true
      uses_temporal: true
  '14':
    name: Distributed Data
    overlay: metropolis
    workers_range: "10,001-25,000"
    roadmap_ref: Phase 14 ‚Äì Distributed Data
    primary_goal: CockroachDB migration; global ledger.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: true
      uses_temporal: true
  '15':
    name: Service Mesh
    overlay: metropolis
    workers_range: "25,001-50,000"
    roadmap_ref: Phase 15 ‚Äì Service Mesh
    primary_goal: mTLS + policy-as-code everywhere.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: true
      uses_temporal: true
  '16':
    name: Multi-Cloud Federation
    overlay: metropolis
    workers_range: "50,001-100,000"
    roadmap_ref: Phase 16 ‚Äì Multi-Cloud Federation
    primary_goal: Backstage portal + federated control plane.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: true
      uses_temporal: true
  '17':
    name: Extreme Write Optimization
    overlay: metropolis
    workers_range: "100,001-250,000"
    roadmap_ref: Phase 17 ‚Äì Extreme Write Optimization
    primary_goal: Scylla firehose for telemetry.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: true
      uses_temporal: true
  '18':
    name: Decentralized Nervous System
    overlay: metropolis
    workers_range: "250,001-500,000"
    roadmap_ref: Phase 18 ‚Äì Decentralized Nervous System
    primary_goal: Federated Kafka per continent.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: true
      uses_temporal: true
  '19':
    name: The Metropolis
    overlay: metropolis
    workers_range: "500,001-1,000,000+"
    roadmap_ref: Phase 19 ‚Äì Planet-Scale AI
    primary_goal: Federated learning + sovereign data at planet scale.
    infra_profile:
      uses_kubernetes: true
      uses_kafka: true
      uses_temporal: true


# ================================
# 1) EXECUTIVE OVERVIEW (ARCH)
# ================================
- path: docs/architecture/EXECUTIVE_OVERVIEW.md
  operation: write
  start_line: 1
  content: |
    # Metropolis ‚Äì Executive Overview

    Metropolis is an **operating system for real-world work**: recurring jobs, field operations, and logistics, run across many cities and regions with strong guarantees for safety, compliance, and economics.

    The system is designed to scale from:
    - a **single region, 1‚Äì10 workers**, to
    - **multi-region, multi-cloud, hundreds of thousands of workers**, with
    - **sovereign data**, **Temporal-owned state**, and **federated AI** as core pillars.

    Metropolis is explicitly aligned with the **19-Phase Roadmap** defined for *Project Bianca* (a cleaning services company used as the primary case study).

    - Business & tech roadmap: `docs/business/phase_roadmap.md`
    - Financial & C-suite view: `docs/business/phase_financials.md`

    ---

    ## Who This Is For

    - **Founders / CEOs** ‚Äì to understand which phase unlocks which business capability.
    - **COO / Ops leadership** ‚Äì to see how work, SLAs, and economics are wired in.
    - **CTO / Architects / Staff Engineers / SREs** ‚Äì to see the technical roadmap and invariants.
    - **Compliance / DPO / Security** ‚Äì to understand data classes, sovereignty, and guardrails.

    ---

    ## The Three Core Pillars

    ### 1. Sovereign Data

    - Each **region** owns its own PII and operational data.
    - Cross-region traffic is explicit, audited, and policy-gated.
    - Data classes and retention live in code: see `governance/data_classes.yaml`.

    **Outcome:** You can add new regions without losing control of where data lives or how it is processed.

    ---

    ### 2. Temporal-Owned State

    - All **important business state transitions** are owned by Temporal workflows:
      - work order lifecycle
      - dispatch / scheduling decisions
      - billing and ledger updates
    - Services become ‚Äústateless brains‚Äù around long-running workflows.

    **Outcome:** Upgrades and incidents are survivable because state is durable and replayable.

    ---

    ### 3. Federated AI

    - Models are trained **locally** per region, with **aggregated learning** across regions.
    - Raw PII stays in-region; only gradient/parameter updates move.
    - Guardrails (OPA + policies) keep AI away from direct DB writes or policy bypass.

    **Outcome:** You get better performance over time without centralizing sensitive data.

    ---

    ## Phase Roadmap (Executive Snapshot)

    Metropolis is designed in **phases**. Each phase assumes a certain **scale** and **org maturity**.

    This is the *high-level* grouping; the **full 19-phase table** with tech injections is in
    `docs/business/phase_roadmap.md`.

    | Phase Range | Label                 | Typical Scale                        | Key Unlocks                                             |
    |-----------: |----------------------|--------------------------------------|--------------------------------------------------------|
    | 1‚Äì3         | Bootstrap             | 1‚Äì5 workers, 1 region                | MVP, free-tier infra, basic scheduling                 |
    | 4‚Äì7         | Early Expansion       | 10‚Äì100 workers, 1‚Äì2 cities           | Finance engine, routing, first workflow orchestration  |
    | 8‚Äì11        | Platform Foundations  | 250‚Äì2,500 workers, multi-city        | Kubernetes, Kafka, digital twin v1, observability      |
    | 12‚Äì16       | Intelligence & Global | 5,000‚Äì100,000 workers, multi-country | Lakehouse, Flink, AI-CEO v1, multi-cloud federation    |
    | 17‚Äì19       | The Metropolis        | 250,000‚Äì1M+ workers, planet-scale    | Scylla, federated Kafka, federated learning, niche RTOS|

    Technical details per phase:

    - Business + technology: `docs/business/phase_roadmap.md`
    - Economics & C-suite: `docs/business/phase_financials.md`
    - Architecture overlays and invariants: `docs/architecture/phase_index.md`
    - Per-category tech audit: `docs/architecture/phase_audit_by_category.md` (TODO stub if desired)

    ---

    ## How To Read The Repo

    1. **Story & business framing**
       - `docs/business/phase_roadmap.md`
       - `docs/business/phase_financials.md`

    2. **Architecture big picture**
       - `docs/architecture/EXECUTIVE_OVERVIEW.md` (this file)
       - `docs/architecture/metropolis_layers.html`
       - `docs/architecture/metropolis_phases_timeline.html`

    3. **Terminology & phases**
       - `docs/architecture/glossary.md`
       - `docs/architecture/phase_index.md`

    4. **Real-world behaviour**
       - `docs/architecture/user_journeys.md`

    5. **Reliability & operations**
       - `docs/architecture/failure_modes.md`
       - `runbooks/` (incident playbooks)

    6. **Data, compliance & sovereignty**
       - `governance/data_classes.yaml`
       - `docs/compliance/*`

    ---

    ## What ‚ÄúGood‚Äù Looks Like At Each Stage

    - **Phase 1‚Äì3 (Bootstrap)**
      - Vercel + Supabase + Rust/Go serverless.
      - Simple schemas, manual runbooks, but **no recurring infra cost**.
      - Metric: `Recurring Cost ‚âà 0`, `Jobs Completed > 0`.

    - **Phase 4‚Äì7 (Systematize & Expand)**
      - Finance engine (ERPNext/Odoo), routing (OSRM + H3), Temporal for workflows, Keycloak for auth.
      - Metric: payroll time drops, travel time optimised, CEO out of the field.

    - **Phase 8‚Äì11 (Platform Foundations)**
      - Kubernetes + Terraform, Vault, Kafka, first ‚ÄúDigital Twin‚Äù, Prometheus + logs + alerting.
      - Metric: MTTR down, deployments safer, event-driven nervous system.

    - **Phase 12‚Äì16 (Intelligence & Globalisation)**
      - Lakehouse + Flink, Triton, Vector DB, feature store, Backstage, multi-cloud federation.
      - Metric: AI-driven optimisation, new markets, resilient global footprint.

    - **Phase 17‚Äì19 (Metropolis)**
      - ScyllaDB for telemetry, federated Kafka, federated learning, high-assurance crypto & niche RTOS at the edges.
      - Metric: planet-scale reliability, privacy-compliant AI, ‚Äúutility-like‚Äù operations.

    For the fully detailed phase-by-phase view (scale, roles, KPIs, valuations), see:
    - `docs/business/phase_roadmap.md`
    - `docs/business/phase_financials.md`

    ---

    ## Next Steps

    - If you‚Äôre a **new engineer**, read:
      - `docs/architecture/dev_getting_started.md`
      - `docs/architecture/user_journeys.md`

    - If you‚Äôre **reviewing the design**:
      - Scan `docs/business/phase_roadmap.md`
      - Skim diagrams in:
        - `docs/architecture/metropolis_layers.html`
        - `docs/architecture/metropolis_phases_timeline.html`

    - If you‚Äôre in **Ops / SRE / Compliance**:
      - `docs/architecture/failure_modes.md`
      - `runbooks/`
      - `governance/data_classes.yaml` and `docs/compliance/*`


# ===========================================
# 2) BUSINESS ROADMAP: 19-PHASE STORY
# ===========================================
- path: docs/business/phase_roadmap.md
  operation: write
  start_line: 1
  content: |
    # 19-Phase Growth & Technology Roadmap (Project Bianca)

    This document is the **business + technology spine** for the Metropolis architecture.

    It describes how *Project Bianca* (a cleaning services company) evolves across 19 phases, and which
    **technical decisions** unlock each stage ‚Äì from ‚ÄúCEO cleans all apartments‚Äù to ‚Äúplanet-scale AI‚Äù.

    Metropolis is the technical architecture that must **enable** this story.

    ---

    ## üóìÔ∏è The 19-Phase Roadmap (Synchronized)

    | Phase | Title | Core Focus | Key Tech Injection (Aligned with Audit) |
    | :--- | :--- | :--- | :--- |
    | **Phase 1** | **Prove the Model** | Solo Founder & MVP. | **Rust, Vercel, Supabase** (Zero-cost bootstrap). |
    | **Phase 2** | **Free the CEO** | First Hire & Reliability. | **Sentry** (Error Logging), Dedicated DB instance. |
    | **Phase 3** | **Systematize Scheduling** | Internal Tools & Logic. | **Feature Flags**, **SQLite** (Edge Cache), **Cal.com** (Ref). |
    | **Phase 4** | **Automate Finance** | Invoicing/Payroll Engine. | **ERPNext/Odoo** (Backoffice), **SQLAlchemy** (non-core). |
    | **Phase 5** | **Optimize Routing** | Geospatial Integration. | **OSRM/Valhalla** (Routing), **Uber H3**, **MQTT** (Transport). |
    | **Phase 6** | **Improve Performance** | Workflow Durability. | **Temporal** (Orchestration), *Drop Celery*. |
    | **Phase 7** | **Multi-City Expansion** | Sovereign Identity. | **Keycloak** (Auth), Internal Search. |
    | **Phase 8** | **Kubernetes Migration** | Container Orchestration. | **Kubernetes**, **Terraform**, **Envoy**, **Vault**, **ArgoCD**. |
    | **Phase 9** | **Event-Driven Architecture** | The Nervous System. | **Apache Kafka** (Event Bus). |
    | **Phase 10** | **"Digital Twin" v1** | Real-time Dashboard. | **Edge Compute (K3s)**, **FreeSO** (Sim DNA), **Deck.gl**. |
    | **Phase 11** | **True Observability** | Metrics/Tracing. | **Prometheus**, **Central Logs**, **SLO Alerts**. |
    | **Phase 12** | **Data-Driven Intelligence** | AI v1 & Stream Proc. | **Lakehouse**, **Apache Flink**, **Triton**, **Vector DB**. |
    | **Phase 13** | **Multi-Region Expansion** | National Scale. | **Anycast LB**, **Service Discovery**, **Nautobot**. |
    | **Phase 14** | **Distributed Data** | Global Ledger. | **CockroachDB** (Distributed SQL), Data Governance. |
    | **Phase 15** | **Service Mesh** | Networking & mTLS. | **Linkerd** (Primary Mesh), **OPA/Cedar**, **SPIRE**. |
    | **Phase 16** | **Multi-Cloud Federation** | Global Resilience. | **Backstage** (Portal), Federated Control Plane. |
    | **Phase 17** | **Extreme Write Optimization** | High-Velocity Telemetry. | **ScyllaDB** (NoSQL), *Drop Cassandra/FoundationDB*. |
    | **Phase 18** | **Decentralized Nervous System** | Federated Kafka. | **Federated Kafka** Clusters. |
    | **Phase 19** | **The Metropolis** | Planet-Scale AI. | **Federated Learning**, **Verified Crypto**, **Niche OS (Limit)**. |

    ---

    ## 1. Abstract & Purpose for the AI Architect

    This document outlines the complete, **19-phase growth trajectory** of the "Project Bianca" cleaning services company.
    It serves as the primary, real-world case study for the architectural design work in this repo.

    Your task, as the AI Architect (or human architect reading this), is to design a technical architecture that:

    - **Supports and enables** each phase.
    - Justifies every **technology choice** in the context of:
      - operational scale,
      - financial reality,
      - primary business goal of that phase.
    - Ensures **smooth transition** between phases:
      - The success of one phase must not create a wall for the next.

    This is the story of a company's evolution.  
    The Metropolis architecture is its backbone.

    ---

    ## 2. The Complete 19-Phase Growth & Technology Roadmap

    | Phase | Scale (Workers) | Primary Goal | Financial & Business Reality | CTO Focus & Role | Key Architectural Decisions & Tech Stack |
    | :--- | :--- | :--- | :--- | :--- | :--- |
    | **1** | **1 (CEO)** | **Prove the Model.** | CEO performs all cleaning. Every krone of profit is critical. The biggest bottleneck is the CEO's physical time. | **Solo Builder** | **Bootstrap Stack (0 kr/mo):** Vercel (Hobby), Supabase (Free Tier), Rust/Go (Serverless). **No recurring cost is the key constraint.** |
    | **2** | **CEO + 1 Worker** | **Free the CEO.** | First employee hired. CEO transitions from primary worker to full-time trainer and manager. Reliability becomes paramount. | **Pragmatic Founder** | **Upgrade to Pragmatic Powerhouse (~750 kr/mo):** The free DB *sleeps*, which is unacceptable. Migrate backend to a dedicated container and database to a paid, "always-on" tier. Integrate **Sentry** for critical error logging. |
    | **3** | **5 Workers** | **Systematize Scheduling.** | CEO now manages a small team. Scheduling via phone calls and spreadsheets is becoming chaotic and inefficient. | **First Engineer** | **Build the "Internal Tools MVP":** Focus shifts to the first custom **Admin Dashboard** (Next.js) & **Worker App**. Introduce **Feature Flags** to safely test new scheduling rules. Use **SQLite** on edge devices for offline-first caching. |
    | **4** | **10 Workers**| **Automate Finance.** | Invoicing and payroll are now a significant administrative burden. Mistakes are costly. | **Full-Stack Developer** | **Build the "Finance Engine":** Integrate **ERPNext** or **Odoo** components for the ledger. Develop custom modules for automated invoicing, ensuring strict data consistency in the PostgreSQL database. |
    | **5** | **25 Workers** | **Optimize Routing.** | The team is now large enough that inefficient travel routes between jobs are a major cost center. | **Backend Engineer** | **Introduce Geospatial Capabilities:** Integrate **OSRM / Valhalla** for routing engine and **Uber H3** for spatial indexing. Add **MQTT** for lightweight worker telemetry transport. |
    | **6** | **50 Workers** | **Improve Performance.** | The single backend application is showing strain under complex workflow logic (cancellations, rescheduling). | **Architect & Team Lead** | **Introduce Workflow Orchestration:** Replace ad-hoc queues with **Temporal**. This guarantees durability for long-running workflows (e.g., "Job Completion Saga"). **Drop Celery/RabbitMQ** in favor of this robust pattern. |
    | **7** | **100 Workers** | **Prepare for Multi-City Expansion.** | The company is ready to launch in a new city. Identity and compliance become complex. | **Architect & Team Lead** | **Sovereign Identity:** Implement **Keycloak** to handle Org Roles and city-specific compliance. Extract the most critical logic (Scheduling) into the first true Microservice. |
    | **8** | **250 Workers** | **Migrate to Kubernetes.** | Managing containers manually is no longer viable. Need for automated scaling and reproducibility. | **Head of Engineering** | **The "Great Migration" Part 1:** Move to **Kubernetes**. Adopt **Terraform** for Infrastructure as Code (IaC). Implement **Vault** for secrets and **Envoy Gateway** for ingress. |
    | **9** | **500 Workers** | **Establish Event-Driven Architecture.** | Direct service-to-service API calls are becoming brittle. A change in one service can cause cascading failures. | **Platform Architect** | **Implement the "Nervous System":** Introduce **Apache Kafka** as the central event bus. Services now communicate by publishing/subscribing to events (`JobCreated`, `WorkerLocationUpdated`). |
    | **10** | **1,000 Workers** | **Build the "Digital Twin" v1.** | Management needs a real-time, high-level view of all operations. | **Platform Architect** | **Build the Presentation Layer:** Deploy **Edge Compute (K3s)** nodes to vans/hubs to feed the twin. Visualize via **deck.gl**. Use **FreeSO** logic patterns for agent behavior simulation ("The Matrix"). |
    | **11**| **2,500 Workers**| **Achieve True Observability.**| The distributed system is now so complex that when something breaks, it's difficult to know *where* and *why*. | **Head of SRE/Platform** | **Implement the Observability Stack:** Deploy **Prometheus** for metrics, **Centralized Logging**, and **SLO-based Alerting**. This is non-negotiable for operational stability. |
    | **12**| **5,000 Workers**| **Data-Driven Intelligence.** | The company has collected years of data. Time to use it for competitive advantage. | **Head of Data & AI** | **Build the Intelligence Platform:** Create a **Lakehouse**. Deploy **Apache Flink** for real-time stream processing/aggregations. Implement **Triton Inference** for the "AI-CEO" microservice. |
    | **13**| **10,000 Workers** | **Go Multi-Region (National).** | An outage in a single data center would be catastrophic. | **Principal Architect** | **The "Great Migration" Part 2:** Multi-Region K8s. Implement **Anycast Load Balancing** and Global **Service Discovery** to route traffic and propagate config across regions. |
    | **14**| **25,000 Workers** | **Solve Distributed Data.** | A single PostgreSQL instance cannot handle the continental-scale load. | **Principal Architect** | **Migrate to Distributed SQL:** Zero-downtime migration to **CockroachDB**. Establish strict **Data Governance** (Lineage/PII tracking). Phase out legacy Supabase/MySQL instances. |
    | **15**| **50,000 Workers** | **Master Microservice Networking.** | Managing network security and routing across thousands of instances is impossible manually. | **Head of Infrastructure** | **Implement a Service Mesh:** Deploy **Linkerd** (Primary) for mTLS and observability. Implement **OPA/Cedar** for Policy-as-Code and **SPIRE** for workload identity. |
    | **16**| **100,000 Workers**| **Go Multi-Cloud (Global).** | Vendor lock-in is a major strategic risk. | **Global Head of Technology** | **Federate Across Clouds:** Deploy across AWS, GCP, Azure. Implement **Backstage** as the Developer Portal to standardize "Golden Paths" across the global engineering team. |
    | **17**| **250,000 Workers**| **Optimize for Extreme Write Load.**| Real-time telemetry (pings every second) is overwhelming the transactional DB. | **Distinguished Engineer** | **Introduce Specialized NoSQL:** Deploy **ScyllaDB** specifically for the high-velocity "Firehose" of worker location/event data. This offloads the write burden from CockroachDB. |
    | **18**| **500,000 Workers**| **Decentralize the Nervous System.** | A single-continent Kafka cluster is a bottleneck. | **Distinguished Engineer** | **Federate the Message Broker:** Evolve into a **Federated Kafka** architecture. Each continent has its own cluster that communicates asynchronously. |
    | **19**| **1,000,000+ Workers** | **Achieve Planet-Scale AI.** | Training a monolithic "AI-CEO" is no longer feasible or legal. | **Chief AI Officer** | **Implement Federated Learning:** Train models locally on regional data. Utilize **Verified Crypto (HACL*)** for hyper-secure communications. Limit use of niche kernels (seL4) to specific robotics edges. |

    ---

    ## 3. Where This Connects To The Code

    - **Architecture overview:** `docs/architecture/EXECUTIVE_OVERVIEW.md`
    - **Phase overlays & tech invariants:** `docs/architecture/phase_index.md`
    - **User journeys & flows:** `docs/architecture/user_journeys.md`
    - **Financial & C-suite view:** `docs/business/phase_financials.md`


# ==================================================
# 3) BUSINESS: C-SUITE & FINANCIAL GROWTH TABLE
# ==================================================
- path: docs/business/phase_financials.md
  operation: write
  start_line: 1
  content: |
    # C-Suite & Financial Growth Table (Project Bianca)

    This document mirrors the **19-phase roadmap**, but from the angle of:

    - revenue,
    - salaries and margins,
    - valuation,
    - and **C-suite goals / KPIs**.

    It is the primary reference for aligning **architecture decisions** with **business reality**.

    ---

    ## 3. The C-Suite & Financial Growth Table

    > All numbers are approximate and scenario-based; replace with real numbers for your deployment.

    | Phase | Scale (Workers) | Customers Served (Recurring) | Jobs per Week (Approx.) | Monthly Revenue (Approx.) | Monthly Salaries (Approx.) | Gross Margin (Approx.) | Est. Valuation | CEO (Chief Executive Officer) | CTO (Chief Technology Officer) | COO (Chief Operating Officer) | CRO (Chief Revenue Officer) | CFO (Chief Financial Officer) | CPO (Chief People Officer) | CProdO (Chief Product Officer) | CMO (Chief Marketing Officer) | CAIO (Chief AI Officer) | CLO (Chief Legal Officer) | CISO (Chief Security Officer) |
    | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
    | **1** | 1 (CEO) | ~20 | 10 | $8.7K | $0 | **$8.7K** | **~$50K** | **Goal:** Prove the model.<br>**KPI:** `Jobs Completed > 0` | **Goal:** Build MVP.<br>**KPI:** `Recurring Cost = $0` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **2** | 2 | ~40 | 20 | $17.3K | $9.1K | **$8.2K** | **~$250K** | **Goal:** Free myself from labor.<br>**KPI:** `CEO Hours Cleaning ‚Üí 0` | **Goal:** Ensure reliability.<br>**KPI:** `Platform Uptime = 99.9%` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **3** | 5 | ~100 | 50 | $43.3K | $22.8K | **$20.5K** | **~$1M** | **Goal:** Systematize training.<br>**KPI:** `Time to New Worker's 1st Solo Job < 3 days` | **Goal:** Eliminate spreadsheets.<br>**KPI:** `Manual Scheduling Ops ‚Üí 0` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **4** | 10 | ~200 | 100 | $86.6K | $45.6K | **$41.0K** | **~$2M** | **Goal:** Build management.<br>**KPI:** `Hire 1st Team Lead` | **Goal:** Automate finance.<br>**KPI:** `Time on Payroll < 1 hr/wk` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **5** | 25 | ~500 | 250 | $217K | $114K | **$103K** | **~$5M** | **Goal:** Create a sales process.<br>**KPI:** `New Customers / Week > 5` | **Goal:** Optimize routing.<br>**KPI:** `Avg. Travel Time < 20 mins` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **6** | 50 | ~1,000 | 500 | $433K | $228K | **$205K** | **~$10M** | **Goal:** Secure seed funding.<br>**KPI:** `Raise > $500K` | **Goal:** Handle peak load.<br>**KPI:** `API p95 Latency < 200ms` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **7**| **100**| ~2,000 | 1,000 | $866K | $456K | **$410K** | **~$25M** | **Goal:** Expand to City #2.<br>**KPI:** `Revenue from City #2 > 0` | **Goal:** Prepare for microservices.<br>**KPI:** `Extract 1st Service` | **[Hired] Goal:** Build the playbook.<br>**KPI:** `(Time to Launch City #2) < 50% of (Time to Launch City #1)` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **8**| 250 | ~5,000 | 2,500 | $2.2M | $1.1M | **$1.1M** | **~$75M** | **Goal:** Hire VPs.<br>**KPI:** `Executive Team Hired > 1` | **Goal:** Go Cloud-Native.<br>**KPI:** `Services on Kubernetes = 100%` | **Goal:** Optimize inter-city ops.<br>**KPI:** `Standardize Supply Chain` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **9**| **500**| ~10,000 | 5,000 | $4.3M | $2.3M | **$2.0M** | **~$200M** | **Goal:** Secure Series A.<br>**KPI:** `Raise > $5M` | **Goal:** Achieve event-driven arch.<br>**KPI:** `API Calls Replaced by Events > 50%` | **Goal:** Manage regional GMs.<br>**KPI:** `Regional P&L > 0` | **[Hired] Goal:** Build a sales engine.<br>**KPI:** `CAC < LTV` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **10**| 1,000 | ~20,000 | 10,000 | $8.7M | $4.6M | **$4.1M** | **~$500M** | **Goal:** National brand presence.<br>**KPI:** `Operate in > 5 major cities` | **Goal:** Launch Digital Twin v1.<br>**KPI:** `Real-time KPIs on Dashboard = 10` | **Goal:** National-scale logistics.<br>**KPI:** `Avg. Supply Cost / Job (National) - 5%` | **Goal:** Dominate national market.<br>**KPI:** `National Market Share > 10%` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **11**| **2,500**| ~50,000 | 25,000 | $21.7M | $11.4M | **$10.3M**| **~$1.5B** | **Goal:** Plan international expansion.<br>**KPI:** `Launch Country #2` | **Goal:** Full observability.<br>**KPI:** `MTTR < 15 mins` | **Goal:** International playbook.<br>**KPI:** `Time to Launch Country #2 < 6 months` | **Goal:** Build int'l GTM.<br>**KPI:** `Revenue from Country #2 > 0` | **[Hired] Goal:** Secure Series B.<br>**KPI:** `Raise > $25M` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **12**| 5,000 | ~100,000 | 50,000 | $43.3M | $22.8M | **$20.5M**| **~$4B** | **Goal:** Establish global leadership.<br>**KPI:** `Hire Continental VPs` | **Goal:** Launch AI-CEO v1.<br>**KPI:** `AI Optimizations Implemented > 5` | **Goal:** Continental supply chain.<br>**KPI:** `Cross-border Time < 48 hrs` | **Goal:** Win multiple countries.<br>**KPI:** `Market Leader in > 3 Countries` | **Goal:** IPO readiness.<br>**KPI:** `Achieve GAAP Compliance` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **13**| **10,000**| ~200,000 | 100,000 | $86.6M | $45.6M | **$41.0M**| **~$10B** | **Goal:** Strategic M&A.<br>**KPI:** `Acquire 1st Competitor` | **Goal:** Go Multi-Region.<br>**KPI:** `Active Traffic in > 1 Cloud Region` | **Goal:** Manage continental directors.<br>**KPI:** `Continental P&L > 0` | **Goal:** Continental market leadership.<br>**KPI:** `Market Share in EU > 15%` | **Goal:** Manage public finances.<br>**KPI:** `Stock Price (Post-IPO)` | **[Hired] Goal:** Build global culture.<br>**KPI:** `eNPS > 50` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **14**| 25,000 | ~500,000 | 250,000 | $217M | $114M | **$103M** | **~$25B** | **Goal:** Industry leadership.<br>**KPI:** `Define Industry Best Practices` | **Goal:** Solve distributed data.<br>**KPI:** `Migrate 100% of DB to CockroachDB` | **Goal:** Global operational excellence.<br>**KPI:** `Global OpEx +2%` | **Goal:** Global sales machine.<br>**KPI:** `Global CAC -10%` | **Goal:** Drive shareholder value.<br>**KPI:** `EPS > 0` | **Goal:** Global talent acquisition.<br>**KPI:** `Time to Hire (Senior) < 45 days` | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
    | **15**| **50,000**| ~1 Million | 500,000 | $433M | $228M | **$205M** | **~$50B** | **Goal:** Diversify business.<br>**KPI:** `Launch 1st Non-Cleaning Service` | **Goal:** Master microservice networking.<br>**KPI:** `100% of Services in Service Mesh` | **Goal:** Extreme efficiency.<br>**KPI:** `Worker Idle Time < 5%` | **Goal:** New revenue lines.<br>**KPI:** `Revenue from New Services > 0` | **Goal:** Capital allocation.<br>**KPI:** `ROIC > 15%` | **Goal:** Executive development.<br>**KPI:** `Internal Leadership Promotions > 50%` | **[Hired] Goal:** Own product vision.<br>**KPI:** `Worker App Rating > 4.8` | ‚Äî | ‚Äî | ‚Äî |
    | **16**| **100,000**| ~2 Million | 1 Million | $866M | $456M | **$410M** | **~$100B**| **Goal:** Global brand recognition.<br>**KPI:** `Brand Awareness > 50%` | **Goal:** Go Multi-Cloud.<br>**KPI:** `Active Traffic in > 1 Cloud Provider` | **Goal:** Predictive operations.<br>**KPI:** `Forecast vs. Actual < 5%` | **Goal:** Create new markets.<br>**KPI:** `Launch Service in Untapped Continent` | **Goal:** Manage global treasury.<br>**KPI:** `Optimize Global Tax` | **Goal:** Build legacy.<br>**KPI:** `Launch Corporate University` | **Goal:** Platform strategy.<br>**KPI:** `3rd Party Devs on Platform > 0` | **[Hired] Goal:** Global brand.<br>**KPI:** `Share of Voice > 25%` | ‚Äî | ‚Äî | ‚Äî |
    | **17**| **250,000**| ~5 Million | 2.5 Million | $2.2B | $1.1B | **$1.1B** | **~$250B**| **Goal:** Set global labor standards.<br>**KPI:** `Global Worker Satisfaction > 90%` | **Goal:** Optimize for extreme scale.<br>**KPI:** `p99 Latency < 50ms Globally` | **Goal:** Automate global logistics.<br>**KPI:** `Human Intervention in Supply Chain < 10%` | **Goal:** Platform revenue.<br>**KPI:** `Platform Revenue > $100M` | **Goal:** Global risk.<br>**KPI:** `Hedge 100% Currency Exposure` | **Goal:** Global talent mobility.<br>**KPI:** `Cross-Continental Transfers > 100/yr` | **Goal:** Product ecosystem.<br>**KPI:** `Marketplace Apps > 100` | **Goal:** Category leadership.<br>**KPI:** `Category Creator` | **[Hired] Goal:** Strategic AI.<br>**KPI:** `AI-driven Efficiency > 5%` | ‚Äî | ‚Äî |
    | **18**| **500,000**| ~10 Million | 5 Million | $4.3B | $2.3B | **$2.0B** | **~$500B**| **Goal:** Long-term legacy.<br>**KPI:** `Publish 1st Global Impact Report` | **Goal:** Planet-scale resilience.<br>**KPI:** `Survive Full Cloud Provider Outage` | **Goal:** Operational perfection.<br>**KPI:** `Global Worker Idle Time < 2%` | **Goal:** Ecosystem dominance.<br>**KPI:** `Platform Revenue > $1B` | **Goal:** Influence global finance.<br>**KPI:** `Market Cap > $50B` | **Goal:** Leadership succession.<br>**KPI:** `Internal CEO Successor Identified` | **Goal:** New ventures.<br>**KPI:** `Launch 1st Spinoff Company` | **Goal:** Legacy branding.<br>**KPI:** `Become a "Verb"` | **Goal:** AI leadership.<br>**KPI:** `Publish > 5 SOTA Papers/yr` | **[Hired] Goal:** Global legal.<br>**KPI:** `Manage 100+ Legal Jurisdictions` | **[Hired] Goal:** Global security.<br>**KPI:** `Time to Contain Breach < 5 mins` |
    | **19**| **1M+** | ~20 Million | 10 Million | $8.7B | $4.6B | **$4.1B** | **~$1T+** | **Goal:** Guide the industry.<br>**KPI:** `Set Ethical Standards for AI in Labor` | **Goal:** Push state-of-the-art.<br>**KPI:** `Achieve Federated Learning` | **Goal:** Drive planetary efficiency.<br>**KPI:** `Global OpEx +0.1% = >$10M saved` | **Goal:** Become a utility.<br>**KPI:** `Services Deemed "Essential Infrastructure"` | **Goal:** Influence global finance.<br>**KPI:** `Market Cap > $100B` | **Goal:** Global talent incubator.<br>**KPI:** `C-Suite Hires from Internal Promotions = 100%` | **Goal:** Define the future.<br>**KPI:** `Launch "Skunk Works" R&D Division` | **Goal:** Cultural permanence.<br>**KPI:** `Brand Recognised > 95% Globally` | **Goal:** Achieve AGI.<br>**KPI:** `AI-CEO Operates Autonomously` | **Goal:** Shape policy.<br>**KPI:** `Advise Governments on AI & Labor` | **Goal:** Total defense.<br>**KPI:** `Predict and Neutralize Zero-Day Threats` |

    ---

    ## How To Use This Table

    - **Founders / Board**: sanity-check whether the tech roadmap & hiring plan actually support the financial goals.
    - **CTO / Architects**: defend or adjust tech investments per phase.
    - **AI teams**: align model goals with business KPIs (e.g. routing efficiency, idle time, churn).

    See also:

    - `docs/business/phase_roadmap.md`
    - `docs/architecture/EXECUTIVE_OVERVIEW.md`


# ====================================
# 4) PHASE INDEX (ARCH OVERLAYS)
# ====================================
- path: docs/architecture/phase_index.md
  operation: write
  start_line: 1
  content: |
    # Phase Index

    This document ties together **phases**, **overlays**, **infra**, and **economics**.

    For the narrative and business-first view, see:

    - `docs/business/phase_roadmap.md`
    - `docs/business/phase_financials.md`

    For detailed configuration, see:

    - `phase_overlays/*.yaml`
    - `phase_annotations/*.yaml`
    - `phase_economics/*.yaml`
    - `services/core-engine/config/feature_flags.yaml`

    ---

    ## Summary Table (Grouped View)

    | Phase | Overlay     | Typical Workers | Infra Profile                          | Key Features                                       |
    |------:|-------------|-----------------|----------------------------------------|----------------------------------------------------|
    | 1     | bootstrap   | 1‚Äì5             | Vercel + Supabase, single region       | MVP APIs, basic scheduling, zero-cost infra        |
    | 3     | bootstrap   | 5‚Äì20            | Single region, Postgres + caching      | Internal tools, feature flags                      |
    | 5     | expansion   | 20‚Äì80           | 1‚Äì2 regions, OSRM/H3, MQTT             | Routing, geospatial, worker telemetry              |
    | 7     | expansion   | 80‚Äì150          | 2+ cities, Keycloak, Temporal partial  | Sovereign identity, first microservices            |
    | 9     | metropolis  | 250‚Äì500         | Kafka, K8s, Vault, Envoy               | Event-driven arch, nervous system                  |
    | 11    | metropolis  | 2,500           | Observability stack, SLOs              | True observability, SLO-driven operations          |
    | 13    | metropolis  | 10,000          | Multi-region K8s, Anycast LB           | National-scale routing & config                    |
    | 14    | metropolis  | 25,000          | CockroachDB, strong governance         | Global ledger, distributed SQL                     |
    | 17    | metropolis  | 250,000         | ScyllaDB, specialised telemetry infra  | Extreme write paths for telemetry                  |
    | 19    | metropolis  | 1,000,000+      | Federated Kafka, federated learning    | Planet-scale AI & operations                       |

    ---

    ## Mapping: Phases ‚Üí Overlays ‚Üí Feature Flags

    Conceptual mapping; concrete values live in `phase_overlays/*` and `feature_flags.yaml`.

    | Phase | Overlay    | Example Feature Toggles (should exist in `feature_flags.yaml`)                   |
    |------:|------------|----------------------------------------------------------------------------------|
    | 1     | bootstrap  | `kafka_event_bus=false`, `temporal_core=false`, `multi_region_routing=false`    |
    | 3     | bootstrap  | `feature_flags_core=true`, `edge_cache_sqlite=true`                             |
    | 5     | expansion  | `routing_engine_enabled=true`, `worker_telemetry_streams=true`                  |
    | 7     | expansion  | `keycloak_auth=true`, `multi_city_enabled=true`                                 |
    | 9     | metropolis | `kafka_event_bus=true`, `temporal_core=true`                                    |
    | 11    | metropolis | `full_observability=true`, `slo_alerting=true`                                  |
    | 12    | metropolis | `lakehouse_enabled=true`, `flink_streams=true`, `vector_db_enabled=true`        |
    | 14    | metropolis | `cockroach_core=true`, `global_ledger=true`, `data_governance_enforced=true`    |
    | 17    | metropolis | `scylla_telemetry=true`, `firehose_telemetry=true`                              |
    | 19    | metropolis | `federated_learning=true`, `ai_governor_strict=true`                            |

    ---

    ## Overlay Invariants

    These invariants should be reflected in `phase_overlays/*.yaml`:

    ### `bootstrap` overlay

    - `max_regions <= 1`
    - `kafka_event_bus = false`
    - `federated_learning = false`
    - No cross-region data replication
    - Single primary DB (Supabase ‚Üí Postgres)

    ### `expansion` overlay

    - `1 < max_regions <= 3`
    - `kafka_event_bus = true` (or at least introduced)
    - `temporal_core` may be partially enabled (subset of flows)
    - OSRM/H3 configured for routing
    - Clear separation between region-local PII and global aggregates

    ### `metropolis` overlay

    - `max_regions > 3`
    - All critical workflows are **Temporal-owned**
    - Kafka federation in place for inter-region events
    - Global ledger enabled; idempotent billing guaranteed
    - Lakehouse + Flink + Feature Store available (phase dependent)
    - AI is guarded by policies (`ai_no_db_write`, `cross_region_egress`, etc.)

    ---

    ## Economics Snapshot Per Phase

    High-level economics should be captured in `phase_economics/phase_XX.yaml`:

    - `monthly_salaries_eur`
    - `infra_cost_estimate_eur`
    - `target_gross_margin_pct`
    - `target_slo_breaches_per_month`
    - `target_nps` (or worker satisfaction proxy)

    For canonical numbers and C-suite goals, use:

    - `docs/business/phase_financials.md`

    ---

    ## Where To Go Next

    - For flows per phase: `docs/architecture/user_journeys.md`
    - For failures per component: `docs/architecture/failure_modes.md`
    - For data & sovereignty: `governance/data_classes.yaml` and `docs/compliance/*`


# ==========================
# 5) GLOSSARY
# ==========================
- path: docs/architecture/glossary.md
  operation: write
  start_line: 1
  content: |
    # Glossary

    A quick reference for terms used across the Metropolis spec and repo.

    ---

    ### Region

    A logical and physical deployment boundary (e.g. `eu-west-1`, `us-central-1`) with:

    - Its own databases
    - Its own services
    - Its own incident / on-call context

    **Rule:** PII stays in its home region unless an explicit, audited policy allows egress.

    ---

    ### Worker

    A person in the field doing the actual jobs (cleaning, maintenance, logistics, etc.). They use the **worker app** to:

    - receive work orders,
    - update status,
    - navigate to locations,
    - optionally see AI-driven hints or routing.

    ---

    ### Job

    A unit of work to be performed, usually customer-facing, e.g. ‚ÄúClean apartment at 10:00‚Äù.

    Jobs are often recurring and belong to **contracts** or **subscriptions**.

    ---

    ### Work Order

    The internal operational representation of a job:

    - Includes job details, worker assigned, timing, state machine.
    - Owned by a Temporal workflow in advanced phases.
    - Has clear states: `created ‚Üí assigned ‚Üí en_route ‚Üí in_progress ‚Üí completed ‚Üí billed`.

    ---

    ### Overlay

    A **configuration layer** applied on top of the base system to represent a given **phase**:

    - `bootstrap`, `expansion`, `metropolis`.
    - Controls feature flags, infra choices, and defaults.
    - Defined in `phase_overlays/*.yaml`.

    ---

    ### Phase

    A discrete stage of company and system maturity (1‚Äì19):

    - Each phase has:
      - expected scale (workers, regions),
      - infra profile,
      - feature toggles,
      - economics snapshot.
    - See `docs/business/phase_roadmap.md` and `docs/business/phase_financials.md`.

    ---

    ### SURVIVAL GOAL = REGION_FAILURE

    Design principle: the system must **survive a full region outage** without losing:

    - business critical data,
    - money in the ledger,
    - the ability to eventually reconcile work orders.

    Global components (global ledger, configuration, audit) must be designed with this in mind.

    ---

    ### Federated Gym

    The set of components and processes that support **federated learning**:

    - Collects anonymised / aggregated telemetry from each region.
    - Trains models per region and aggregates updates.
    - Keeps PII and raw data in-region.
    - See phases 12‚Äì19 for when this is active.

    ---

    ### Global Governor

    A component (or set of policies + services) responsible for:

    - Cross-region policy enforcement.
    - AI guardrails (e.g. AI cannot directly write to DB).
    - Cross-region data egress decisions.

    Often implemented via OPA policies, API gateways, and Linkerd/Envoy policies.

    ---

    ### Actuation Boundary

    The boundary where **decisions turn into actions** in the real world:

    - Assigning a worker to a job.
    - Changing a job state (e.g. cancel, reschedule).
    - Charging a customer or paying a worker.

    **Rule:** Any logic that crosses the actuation boundary must be:

    - observable (metrics, logs),
    - auditable,
    - ideally owned by Temporal workflows.

    ---

    ### Data Class

    A named category of data with:

    - sensitivity (e.g. PII, financial, operational),
    - legal basis,
    - retention rules,
    - sovereignty requirements.

    Defined in `governance/data_classes.yaml`.

    ---

    ### SLO

    Service Level Objective:

    - A measurable target (e.g. "99.5% of work-order updates succeed in 30 days").
    - Implemented in `slo/*.yaml` with PromQL expressions.
    - Used in incident response and capacity planning.

    ---

    ### DSR (Data Subject Request)

    Request by a person (worker or customer) to exercise their data rights:

    - access, rectification, erasure, etc.
    - Handled via a runbook (see `runbooks/dsr-request.md`).

    ---

    ### Game Day / Chaos Drill

    A **planned failure simulation** to validate:

    - SLOs,
    - runbooks,
    - on-call readiness.

    Examples: killing a region, adding network latency, breaking Kafka links.


# ====================================
# 6) DEV GETTING STARTED
# ====================================
- path: docs/architecture/dev_getting_started.md
  operation: write
  start_line: 1
  content: |
    # Developer Getting Started

    This guide gets you from **clone ‚Üí Phase 1 running locally** as fast as possible.

    Phase 1 corresponds to **‚ÄúProve the Model‚Äù** in `docs/business/phase_roadmap.md`.

    ---

    ## 1. Prerequisites

    - Docker + Docker Compose (or a local K8s dev cluster, if provided)
    - `make` (optional but recommended)
    - `psql` or your favourite SQL client
    - `curl` or HTTP client (Insomnia, Postman, etc.)

    ---

    ## 2. Clone the Repo

    ```bash
    git clone <YOUR_METROPOLIS_REPO_URL> metropolis
    cd metropolis
    ```

    ---

    ## 3. Start the Local Stack (Phase 1 Profile)

    > Phase 1 is **single region**, no Kafka, no Temporal. Ideal for new devs.

    ```bash
    # Example script ‚Äì adapt to your actual script name
    ./scripts/dev/start_local_stack_phase1.sh
    ```

    This should start:

    - API gateway / public API
    - Core engine / domain services
    - Postgres (or single-region Cockroach)
    - Any supporting infra needed for Phase 1

    If your stack uses Docker Compose directly:

    ```bash
    docker compose -f local/dev/phase1-compose.yml up
    ```

    ---

    ## 4. Apply Database Migrations

    ```bash
    # Example ‚Äì adapt to your migration tooling
    ./scripts/dev/migrate_phase1.sh
    ```

    This should:

    - Apply base schema migrations (e.g. `001_*`, `002_*`)
    - Seed a minimal set of:
      - customers,
      - workers,
      - example work orders.

    ---

    ## 5. Verify the API Is Up

    Assuming the public API is on `http://localhost:8080`:

    ```bash
    curl http://localhost:8080/health
    ```

    You should see a small JSON payload like:

    ```json
    {"status":"ok","phase":"1","overlay":"bootstrap"}
    ```

    (Actual shape may differ; adjust as needed.)

    ---

    ## 6. Create a Work Order (Phase 1)

    ```bash
    curl -X POST http://localhost:8080/v1/work-orders \
      -H "Content-Type: application/json" \
      -d '{
        "customer_id": "cust_demo_1",
        "address": "Example Street 1",
        "scheduled_at": "2025-01-01T10:00:00Z",
        "duration_minutes": 90,
        "notes": "Initial demo job"
      }'
    ```

    Expected behaviour:

    - API returns a `work_order_id`.
    - A row appears in the `work_order` table in your DB.

    ---

    ## 7. List Work Orders

    ```bash
    curl "http://localhost:8080/v1/work-orders?region=local&state=created"
    ```

    You should see your newly created work order.

    ---

    ## 8. Dev Profiles for Later Phases

    To simulate more advanced phases locally, we use **dev profiles**:

    - `local/dev/phases/phase1/`
    - `local/dev/phases/phase6/`
    - `local/dev/phases/phase9/`
    - `local/dev/phases/phase13/`
    - `local/dev/phases/phase19/`

    Each profile defines:

    - services to run,
    - migrations to apply,
    - feature flags to enable.

    Example:

    ```bash
    ./scripts/dev/start_local_stack_phase9.sh
    ./scripts/dev/migrate_phase9.sh
    ```

    This should:

    - enable Kafka + Temporal,
    - enable the global ledger,
    - use the `metropolis` overlay.

    ---

    ## 9. Where To Look When You Get Lost

    - **Business story & numbers:**  
      `docs/business/phase_roadmap.md`, `docs/business/phase_financials.md`

    - **Architecture big picture:**  
      `docs/architecture/EXECUTIVE_OVERVIEW.md`  
      `docs/architecture/metropolis_layers.html`  
      `docs/architecture/metropolis_phases_timeline.html`

    - **Flows & failures:**  
      `docs/architecture/user_journeys.md`  
      `docs/architecture/failure_modes.md`


# ====================================
# 7) METROPOLIS LAYERS DIAGRAM (HTML)
# ====================================
- path: docs/architecture/metropolis_layers.html
  operation: write
  start_line: 1
  content: |
    <!DOCTYPE html>
    <html lang="en">
    <head>
      <meta charset="UTF-8" />
      <title>Metropolis ‚Äì Architecture Layers</title>
      <style>
        body {
          font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
          background: #f5f5f5;
          margin: 0;
          padding: 24px;
        }
        h1 {
          margin-bottom: 4px;
        }
        .subtitle {
          color: #555;
          margin-bottom: 24px;
          font-size: 14px;
        }
        .layer-stack {
          max-width: 900px;
          margin: 0 auto;
        }
        .layer {
          background: white;
          border-radius: 12px;
          padding: 16px 20px;
          margin-bottom: 10px;
          box-shadow: 0 2px 4px rgba(0,0,0,0.05);
          border-left: 4px solid #333;
        }
        .layer-title {
          font-weight: 600;
          margin-bottom: 4px;
        }
        .layer-subtitle {
          font-size: 13px;
          color: #666;
          margin-bottom: 6px;
        }
        .tags {
          font-size: 12px;
          color: #444;
        }
        .tag {
          display: inline-block;
          padding: 2px 8px;
          border-radius: 999px;
          border: 1px solid #ddd;
          margin-right: 4px;
          margin-top: 4px;
        }
        .note {
          max-width: 900px;
          margin: 16px auto 0;
          font-size: 12px;
          color: #666;
        }
      </style>
    </head>
    <body>
      <h1>Metropolis ‚Äì Architecture Layers</h1>
      <div class="subtitle">
        From real-world events at the edge to compliant, auditable state and AI-assisted decisions.
      </div>

      <div class="layer-stack">
        <div class="layer">
          <div class="layer-title">Edge &amp; Clients</div>
          <div class="layer-subtitle">
            Worker app, customer app, web admin, and integrations with external systems.
          </div>
          <div class="tags">
            <span class="tag">Worker App</span>
            <span class="tag">Customer Portal</span>
            <span class="tag">Backoffice</span>
            <span class="tag">3rd-party Integrations</span>
          </div>
        </div>

        <div class="layer">
          <div class="layer-title">APIs &amp; Gateways</div>
          <div class="layer-subtitle">
            Public and private APIs, auth, rate limiting, and early policy enforcement.
          </div>
          <div class="tags">
            <span class="tag">API Gateway</span>
            <span class="tag">AuthN/AuthZ</span>
            <span class="tag">OPA / Policies</span>
          </div>
        </div>

        <div class="layer">
          <div class="layer-title">Core Services</div>
          <div class="layer-subtitle">
            Stateless domain services implementing business logic around work orders, workers, customers, and billing.
          </div>
          <div class="tags">
            <span class="tag">Work Orders</span>
            <span class="tag">Workers</span>
            <span class="tag">Customers</span>
            <span class="tag">Pricing</span>
            <span class="tag">Billing</span>
          </div>
        </div>

        <div class="layer">
          <div class="layer-title">Workflows (Temporal)</div>
          <div class="layer-subtitle">
            Long-running, durable workflows own all critical state transitions and retries.
          </div>
          <div class="tags">
            <span class="tag">DispatchSaga</span>
            <span class="tag">WorkOrderLifecycle</span>
            <span class="tag">BillingSaga</span>
            <span class="tag">GlobalModelUpdate</span>
          </div>
        </div>

        <div class="layer">
          <div class="layer-title">Event Bus &amp; Streaming</div>
          <div class="layer-subtitle">
            Kafka, Flink and related components carrying events within and across regions.
          </div>
          <div class="tags">
            <span class="tag">Kafka</span>
            <span class="tag">Kafka Federation</span>
            <span class="tag">Flink</span>
            <span class="tag">Telemetry</span>
          </div>
        </div>

        <div class="layer">
          <div class="layer-title">Data Stores</div>
          <div class="layer-subtitle">
            Region-local operational data, global ledger, analytics stores, and object storage.
          </div>
          <div class="tags">
            <span class="tag">Postgres / Cockroach</span>
            <span class="tag">Scylla / Cassandra</span>
            <span class="tag">Global Ledger</span>
            <span class="tag">S3 / Blob Storage</span>
          </div>
        </div>

        <div class="layer">
          <div class="layer-title">Governance, SLOs &amp; Observability</div>
          <div class="layer-subtitle">
            Policies, metrics, logs, traces, SLOs, and audit trails that make the system safe to operate.
          </div>
          <div class="tags">
            <span class="tag">OPA Policies</span>
            <span class="tag">SLOs</span>
            <span class="tag">Audit Logs</span>
            <span class="tag">Runbooks</span>
          </div>
        </div>

        <div class="layer">
          <div class="layer-title">Federated AI &amp; Models</div>
          <div class="layer-subtitle">
            Federated training, model serving, and AI guardrails; always respecting data sovereignty.
          </div>
          <div class="tags">
            <span class="tag">Federated Gym</span>
            <span class="tag">Model Serving</span>
            <span class="tag">AI Governor</span>
          </div>
        </div>
      </div>

      <div class="note">
        You can freely edit this HTML file to add or rename components as the architecture evolves.
      </div>
    </body>
    </html>


# ====================================
# 8) PHASES TIMELINE DIAGRAM (HTML)
# ====================================
- path: docs/architecture/metropolis_phases_timeline.html
  operation: write
  start_line: 1
  content: |
    <!DOCTYPE html>
    <html lang="en">
    <head>
      <meta charset="UTF-8" />
      <title>Metropolis ‚Äì Phases Timeline</title>
      <style>
        body {
          font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
          background: #f5f5f5;
          margin: 0;
          padding: 24px;
        }
        h1 {
          margin-bottom: 4px;
        }
        .subtitle {
          color: #555;
          margin-bottom: 24px;
          font-size: 14px;
        }
        .timeline {
          max-width: 1000px;
          margin: 0 auto;
          display: flex;
          flex-direction: column;
          gap: 12px;
        }
        .phase {
          display: flex;
          flex-direction: row;
          align-items: flex-start;
          gap: 12px;
          background: #fff;
          border-radius: 10px;
          padding: 10px 14px;
          box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }
        .phase-num {
          font-weight: 700;
          min-width: 60px;
          text-align: center;
          padding: 6px 8px;
          border-radius: 999px;
          background: #eee;
          font-size: 13px;
        }
        .phase-body {
          flex: 1;
        }
        .phase-title {
          font-weight: 600;
          margin-bottom: 4px;
        }
        .phase-meta {
          font-size: 12px;
          color: #666;
          margin-bottom: 4px;
        }
        .phase-key {
          font-size: 13px;
        }
        .pill {
          display: inline-block;
          font-size: 11px;
          padding: 2px 8px;
          border-radius: 999px;
          border: 1px solid #ddd;
          margin-right: 4px;
          margin-top: 2px;
        }
      </style>
    </head>
    <body>
      <h1>Metropolis ‚Äì Phases Timeline</h1>
      <div class="subtitle">
        A high-level view of how infrastructure and capabilities evolve from Phase 1 to Phase 19.
      </div>

      <div class="timeline">
        <div class="phase">
          <div class="phase-num">1‚Äì3</div>
          <div class="phase-body">
            <div class="phase-title">Bootstrap</div>
            <div class="phase-meta">1 region ¬∑ 1‚Äì20 workers ¬∑ Vercel + Supabase</div>
            <div class="phase-key">
              <div>Zero-cost bootstrap:</div>
              <div>- CEO in the field, then first hires</div>
              <div>- MVP, internal tools, spreadsheets replaced</div>
              <div>- Feature flags & basic scheduling</div>
            </div>
            <div>
              <span class="pill">Overlay: bootstrap</span>
              <span class="pill">Rust/Go</span>
              <span class="pill">Vercel</span>
            </div>
          </div>
        </div>

        <div class="phase">
          <div class="phase-num">4‚Äì7</div>
          <div class="phase-body">
            <div class="phase-title">Finance & Routing & Multi-City</div>
            <div class="phase-meta">1‚Äì2 regions ¬∑ 10‚Äì150 workers ¬∑ ERP + OSRM/H3 + Temporal</div>
            <div class="phase-key">
              <div>- Automated invoicing & payroll</div>
              <div>- OSRM/H3 routing & worker telemetry</div>
              <div>- Temporal for durable workflows</div>
              <div>- Keycloak for sovereign identity</div>
            </div>
            <div>
              <span class="pill">Overlay: expansion</span>
              <span class="pill">ERPNext/Odoo</span>
              <span class="pill">OSRM/H3</span>
            </div>
          </div>
        </div>

        <div class="phase">
          <div class="phase-num">8‚Äì11</div>
          <div class="phase-body">
            <div class="phase-title">Platform Foundations</div>
            <div class="phase-meta">Multi-city ¬∑ 250‚Äì2,500 workers ¬∑ K8s + Kafka + Twin v1</div>
            <div class="phase-key">
              <div>- Kubernetes, Terraform, Vault, Envoy</div>
              <div>- Kafka event bus</div>
              <div>- Digital Twin v1 with K3s edge nodes</div>
              <div>- Prometheus, logs, SLO-based alerts</div>
            </div>
            <div>
              <span class="pill">Overlay: metropolis</span>
              <span class="pill">Kubernetes</span>
              <span class="pill">Kafka</span>
              <span class="pill">Prometheus</span>
            </div>
          </div>
        </div>

        <div class="phase">
          <div class="phase-num">12‚Äì16</div>
          <div class="phase-body">
            <div class="phase-title">Intelligence & Globalisation</div>
            <div class="phase-meta">Multi-country ¬∑ 5,000‚Äì100,000 workers ¬∑ Lakehouse + Flink + Backstage</div>
            <div class="phase-key">
              <div>- Lakehouse + Flink + Triton + Vector DB</div>
              <div>- Feature store & model registry</div>
              <div>- Multi-region & multi-cloud federation</div>
              <div>- Backstage as dev portal</div>
            </div>
            <div>
              <span class="pill">Lakehouse</span>
              <span class="pill">Flink</span>
              <span class="pill">Backstage</span>
            </div>
          </div>
        </div>

        <div class="phase">
          <div class="phase-num">17‚Äì19</div>
          <div class="phase-body">
            <div class="phase-title">The Metropolis</div>
            <div class="phase-meta">Planet-scale ¬∑ 250,000+ workers ¬∑ Scylla + Federated Kafka + Federated Learning</div>
            <div class="phase-key">
              <div>- ScyllaDB for high-velocity telemetry</div>
              <div>- Federated Kafka clusters</div>
              <div>- Federated learning with high-assurance crypto</div>
              <div>- Niche RTOS for robotics edges (optional)</div>
            </div>
            <div>
              <span class="pill">ScyllaDB</span>
              <span class="pill">Federated Kafka</span>
              <span class="pill">Federated Learning</span>
            </div>
          </div>
        </div>
      </div>
    </body>
    </html>


# ====================================
# 9) FAILURE MODES
# ====================================
- path: docs/architecture/failure_modes.md
  operation: write
  start_line: 1
  content: |
    # Failure Modes

    This document lists key components, how they can fail, and where to look when they do.

    It should be read together with:

    - `docs/business/phase_roadmap.md` (to understand which components exist in which phase)
    - `runbooks/*` (for step-by-step responses)

    ---

    ## Table of Common Failure Modes

    | Component          | Symptom                                      | Likely Root Causes                            | SLO / Metrics File                 | Runbook                               |
    |-------------------|-----------------------------------------------|-----------------------------------------------|------------------------------------|----------------------------------------|
    | Region DB         | API 5xx, timeouts, stuck writes              | Node down, disk issues, long-running queries  | `slo/db/*.yaml`                    | `runbooks/db-region-outage.md`        |
    | Global Ledger DB  | Billing stuck, duplicate or missing charges  | Contention, bad migrations, connectivity      | `slo/ledger/*.yaml`                | `runbooks/global-ledger-incident.md`  |
    | Kafka (region)    | Events not processed, large consumer lag     | Broker down, misconfig, full disk             | `slo/kafka/*.yaml`                 | `runbooks/kafka-region-incident.md`   |
    | Kafka Federation  | Cross-region sync stops                      | MirrorMaker down, ACL changes, network issues | `slo/kafka/federation/*.yaml`      | `runbooks/kafka-federation-incident.md` |
    | Temporal          | Workflows stuck, long queue times            | Worker pool down, namespace misconfig         | `slo/temporal/*.yaml`              | `runbooks/temporal-cluster-incident.md` |
    | API Gateway       | 5xx spikes, auth failures                    | Config change, rate limiting, auth backend    | `slo/api_gateway/*.yaml`           | `runbooks/api-gateway-incident.md`    |
    | AI Serving        | Slow or incorrect suggestions                | Model version issues, resource exhaustion     | `slo/ai/*.yaml`                    | `runbooks/ai-serving-incident.md`     |
    | OPA / Policies    | Requests denied unexpectedly                 | Policy change, bad input data                 | `slo/policy/*.yaml`                | `runbooks/policy-incident.md`         |

    ---

    ## Pattern: Region Outage

    **Scenario:** Entire region (`eu-west-1`) goes dark.

    - **Symptoms**
      - All APIs and workers in the region fail.
      - Local DB and Kafka in that region unreachable.
    - **What should still work**
      - Other regions remain healthy.
      - Global ledger remains consistent.
      - Audit logs and configuration remain accessible.
    - **Where to look**
      - `runbooks/region-outage.md`
      - SLO dashboards from `slo/api/*.yaml`, `slo/db/*.yaml`

    ---

    ## Pattern: Global Ledger Incident

    **Scenario:** Billing seems wrong (duplicates, missing charges).

    - **Symptoms**
      - Customer support tickets about wrong invoices.
      - Monitoring shows ledger SLO breach.
    - **Likely causes**
      - Non-idempotent billing flows.
      - Broken Temporal workflow (non-deterministic logic).
      - Bad DB migration on ledger tables.
    - **Where to look**
      - `runbooks/global-ledger-incident.md`
      - `slo/ledger/*.yaml`
      - Recent migrations in `database/migrations/*`

    ---

    ## Pattern: Kafka Federation Incident

    **Scenario:** Cross-region events stop flowing.

    - **Symptoms**
      - Region A doesn‚Äôt see updates from Region B.
      - Consumer lag spikes for federated topics.
    - **Likely causes**
      - MirrorMaker2 process down.
      - ACL updates / certificate issues.
      - Network partition between regions.
    - **Where to look**
      - `runbooks/kafka-federation-incident.md`
      - `slo/kafka/federation/*.yaml`

    ---

    ## Game Day Drills

    For each major component, there should be **planned chaos experiments**:

    - **DB (Region)**
      - Kill primary node, observe failover.
      - Verify SLOs and runbook steps.

    - **Kafka**
      - Stop one broker, observe consumer behaviour.
      - Validate alerting thresholds.

    - **Temporal**
      - Stop all workers for a workflow type.
      - Restart and confirm catch-up behaviour.

    - **Region Outage**
      - Simulate hard cut of one region in staging.
      - Verify traffic shifting, ledger consistency, and runbooks.

    Details for each game day should live inside the relevant runbook.


# ====================================
# 10) USER JOURNEYS
# ====================================
- path: docs/architecture/user_journeys.md
  operation: write
  start_line: 1
  content: |
    # User Journeys

    Three end-to-end flows that demonstrate how the system is meant to be used.

    For which phase introduces which capability, cross-check:

    - `docs/business/phase_roadmap.md`
    - `docs/architecture/phase_index.md`

    ---

    ## 1. Customer Books a Recurring Job

    **Actors:** Customer, Customer App, API, Core Engine, Temporal (later phases), Billing, Ledger

    1. Customer creates a subscription (e.g. weekly cleaning).
    2. API validates input, creates `contract` and `job_template` records.
    3. Scheduler (batch or Temporal workflow):
       - materialises upcoming jobs into `work_order`s,
       - assigns them to regions based on rules and capacity.
    4. Work orders are exposed via:
       - worker app (for eligible workers),
       - backoffice UI.
    5. On completion:
       - Billing workflow calculates charge,
       - Ledger records transaction,
       - Invoices are generated / sent.

    Touchpoints:

    - **APIs:** `POST /v1/subscriptions`, `POST /v1/work-orders`
    - **DB:** `contract`, `subscription`, `work_order`, `invoice`, `ledger_entry`
    - **SLOs:** subscription creation success, work-order creation latency.

    ---

    ## 2. Worker Picks Up and Completes a Job

    **Actors:** Worker, Worker App, Dispatch, Temporal, Ledger

    1. Worker opens the worker app and sees available work orders in their region.
    2. Worker accepts a work order:
       - API triggers `DispatchSaga` (or equivalent).
       - Work order state changes: `created ‚Üí assigned`.
    3. Worker starts navigating:
       - Worker app gets a route (OSRM or similar).
       - Telemetry events stream to Kafka.
    4. Upon arrival and completion:
       - Worker marks job `in_progress ‚Üí completed`.
       - Billing workflow runs:
         - calculates price,
         - writes to ledger,
         - updates worker payout balance.
    5. Any failure in the flow:
       - is retried by Temporal,
       - or results in a clear error and compensating actions.

    Touchpoints:

    - **APIs:** `POST /v1/work-orders/{id}/accept`, `/start`, `/complete`
    - **Workflows:** `DispatchSaga`, `WorkOrderLifecycle`, `BillingSaga`
    - **SLOs:** work-order completion latency, payout correctness (ledger SLOs).

    ---

    ## 3. Federated Model Update

    **Actors:** Worker App, Telemetry, Flink / Streaming, Federated Gym, AI Serving

    _Applicable in phases with federated learning enabled (12+)._

    1. Worker actions and job outcomes emit telemetry events:
       - job type, duration, satisfaction (if known),
       - location grid, time of day (privacy-preserving features).
    2. Events go to Kafka in the region; Flink / stream processors:
       - aggregate them,
       - produce training datasets per region.
    3. Federated Gym:
       - trains local models per region,
       - periodically sends model updates (gradients/weights) to aggregator.
    4. Global aggregator:
       - combines updates,
       - validates against guardrails,
       - produces a new global model version.
    5. AI Serving:
       - rolls out the new model version,
       - traffic is shifted gradually (canary or similar),
       - suggestions in worker app update over time.

    Touchpoints:

    - **Kafka topics:** telemetry, training_data, model_updates.
    - **Services:** Federated Gym, Model Store, Model Serving.
    - **Policies:** `ai_no_db_write`, `cross_region_egress` for model updates.
    - **SLOs:** model serving latency, error rate, rollout health.

    ---

    ## Phase Differences

    - **Early phases (1‚Äì3):**
      - Less automation; some steps may be cron jobs or manual.
      - No Temporal; flows rely on idempotent APIs + retries.

    - **Middle phases (4‚Äì11):**
      - Temporal owns critical workflows.
      - Dispatch and billing become robust and auditable.

    - **Later phases (12+):**
      - Federated learning influences routing and pricing.
      - Policies and observability around AI become critical.

    For more detail per phase, see `docs/business/phase_roadmap.md` and `docs/architecture/phase_index.md`.


# ====================================
# 11) README (ROOT) ‚Äì REPLACE
# ====================================
- path: README.md
  operation: replace
  start_line: 1
  content: |
    # Metropolis

    Metropolis is an **operating system for real-world work** ‚Äì recurring jobs, field operations, and logistics across many cities and regions.

    It is designed to scale from **one region with 1‚Äì10 workers** to **multi-region, multi-cloud deployments with hundreds of thousands of workers**, while keeping:

    - **Sovereign data**
    - **Temporal-owned state**
    - **Federated AI with guardrails**

    The architecture and repo are aligned with a **19-phase roadmap** for *Project Bianca*, a cleaning services company used as a real-world case study.

    - Business roadmap: `docs/business/phase_roadmap.md`
    - Financial & C-suite view: `docs/business/phase_financials.md`
    - Architecture overview: `docs/architecture/EXECUTIVE_OVERVIEW.md`

    ---

    ## Quick Start (Phase 1 ‚Äì ‚ÄúProve the Model‚Äù)

    Phase 1 is the **single-region bootstrap** profile. It‚Äôs the fastest way to run Metropolis locally.

    ```bash
    git clone <YOUR_METROPOLIS_REPO_URL> metropolis
    cd metropolis

    # Start local stack for Phase 1 (adapt command to your repo)
    ./scripts/dev/start_local_stack_phase1.sh

    # Apply Phase 1 migrations
    ./scripts/dev/migrate_phase1.sh
    ```

    Check that the API is up:

    ```bash
    curl http://localhost:8080/health
    ```

    You should see a small JSON payload indicating status and phase.

    Create a test work order:

    ```bash
    curl -X POST http://localhost:8080/v1/work-orders \
      -H "Content-Type: application/json" \
      -d '{
        "customer_id": "cust_demo_1",
        "address": "Example Street 1",
        "scheduled_at": "2025-01-01T10:00:00Z",
        "duration_minutes": 90,
        "notes": "Initial demo job"
      }'
    ```

    ---

    ## Documentation Map

    If you‚Äôre new to the repo, read things in this order:

    1. **Story & business**
       - `docs/business/phase_roadmap.md`
       - `docs/business/phase_financials.md`

    2. **Architecture overview**
       - `docs/architecture/EXECUTIVE_OVERVIEW.md`
       - `docs/architecture/metropolis_layers.html`
       - `docs/architecture/metropolis_phases_timeline.html`

    3. **Vocabulary & phases**
       - `docs/architecture/glossary.md`
       - `docs/architecture/phase_index.md`

    4. **How it behaves in the real world**
       - `docs/architecture/user_journeys.md`

    5. **Reliability & incidents**
       - `docs/architecture/failure_modes.md`
       - `runbooks/` (various incident playbooks)

    6. **Data & compliance**
       - `governance/data_classes.yaml`
       - `docs/compliance/*`

    ---

    ## Phases & Overlays

    Metropolis evolves through **phases** (1‚Äì19), each representing:

    - Scale (workers, regions),
    - Infra profile (DBs, Kafka, Temporal, multi-cloud),
    - Economics (cost vs. margin),
    - Operational maturity (SLOs, runbooks, game days).

    Configuration per phase is expressed via:

    - `phase_overlays/*.yaml`
    - `phase_annotations/*.yaml`
    - `phase_economics/*.yaml`
    - `services/core-engine/config/feature_flags.yaml`

    For the business-driven view, see:

    - `docs/business/phase_roadmap.md`
    - `docs/business/phase_financials.md`

    For the technical invariant view, see:

    - `docs/architecture/phase_index.md`

    ---

    ## Contributing

    If you want to propose changes:

    - **Architecture & data model**
      - Document rationale in `docs/architecture/` or `docs/compliance/`
      - Update `governance/data_classes.yaml` and any affected SLOs / policies.

    - **APIs**
      - Update `services/api/public/openapi.yaml`
      - Add example requests/responses.

    - **Migrations**
      - Add new files in `database/migrations/*`
      - Run dry-run migrations script (if provided) before opening a PR.

    > A more detailed `CONTRIBUTING.md` can be added to define coding standards, review expectations, and CI checks.

    ---

    ## License

    _TODO: Add your license here._

# Insert between line 298 and 300 (before `phase_annotations:`)
phase_economics:
  # Phase 1 ‚Äì Prove the Model
  '1':
    recurring_customers: 3
    jobs_per_week: 10
    monthly_revenue_eur: 8000
    monthly_salaries_eur: 0
    gross_margin_eur: 8000          # 8000 - 0
    gross_margin_pct: 100.0
    est_valuation_eur: 500000
    valuation_multiple_arr: 5.2
    c_suite_roles:
      - "CEO"

  # Phase 2 ‚Äì Free the CEO
  '2':
    recurring_customers: 6
    jobs_per_week: 25
    monthly_revenue_eur: 15000
    monthly_salaries_eur: 3000
    gross_margin_eur: 12000         # 15000 - 3000
    gross_margin_pct: 80.0
    est_valuation_eur: 900000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"

  # Phase 3 ‚Äì Systematize Scheduling
  '3':
    recurring_customers: 10
    jobs_per_week: 50
    monthly_revenue_eur: 25000
    monthly_salaries_eur: 7000
    gross_margin_eur: 18000         # 25000 - 7000
    gross_margin_pct: 72.0
    est_valuation_eur: 1500000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"

  # Phase 4 ‚Äì Automate Finance
  '4':
    recurring_customers: 18
    jobs_per_week: 80
    monthly_revenue_eur: 40000
    monthly_salaries_eur: 15000
    gross_margin_eur: 25000         # 40000 - 15000
    gross_margin_pct: 62.5
    est_valuation_eur: 2400000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"

  # Phase 5 ‚Äì Optimize Routing
  '5':
    recurring_customers: 30
    jobs_per_week: 130
    monthly_revenue_eur: 60000
    monthly_salaries_eur: 25000
    gross_margin_eur: 35000         # 60000 - 25000
    gross_margin_pct: 58.3
    est_valuation_eur: 3600000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"

  # Phase 6 ‚Äì Improve Performance
  '6':
    recurring_customers: 45
    jobs_per_week: 200
    monthly_revenue_eur: 90000
    monthly_salaries_eur: 45000
    gross_margin_eur: 45000         # 90000 - 45000
    gross_margin_pct: 50.0
    est_valuation_eur: 5400000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"

  # Phase 7 ‚Äì Multi-City Expansion
  '7':
    recurring_customers: 70
    jobs_per_week: 350
    monthly_revenue_eur: 150000
    monthly_salaries_eur: 80000
    gross_margin_eur: 70000         # 150000 - 80000
    gross_margin_pct: 46.7
    est_valuation_eur: 9000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"

  # Phase 8 ‚Äì Kubernetes Migration
  '8':
    recurring_customers: 110
    jobs_per_week: 600
    monthly_revenue_eur: 250000
    monthly_salaries_eur: 140000
    gross_margin_eur: 110000        # 250000 - 140000
    gross_margin_pct: 44.0
    est_valuation_eur: 15000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CISO"

  # Phase 9 ‚Äì Event-Driven Architecture
  '9':
    recurring_customers: 170
    jobs_per_week: 900
    monthly_revenue_eur: 400000
    monthly_salaries_eur: 250000
    gross_margin_eur: 150000        # 400000 - 250000
    gross_margin_pct: 37.5
    est_valuation_eur: 24000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CISO"

  # Phase 10 ‚Äì "Digital Twin" v1
  '10':
    recurring_customers: 260
    jobs_per_week: 1400
    monthly_revenue_eur: 650000
    monthly_salaries_eur: 400000
    gross_margin_eur: 250000        # 650000 - 400000
    gross_margin_pct: 38.5
    est_valuation_eur: 39000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CMO"
      - "CISO"

  # Phase 11 ‚Äì True Observability
  '11':
    recurring_customers: 380
    jobs_per_week: 2200
    monthly_revenue_eur: 1000000
    monthly_salaries_eur: 650000
    gross_margin_eur: 350000        # 1000000 - 650000
    gross_margin_pct: 35.0
    est_valuation_eur: 60000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CMO"
      - "CISO"

  # Phase 12 ‚Äì Data-Driven Intelligence
  '12':
    recurring_customers: 550
    jobs_per_week: 3200
    monthly_revenue_eur: 1600000
    monthly_salaries_eur: 1000000
    gross_margin_eur: 600000        # 1600000 - 1000000
    gross_margin_pct: 37.5
    est_valuation_eur: 96000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CMO"
      - "CISO"
      - "CHRO"

  # Phase 13 ‚Äì Multi-Region Expansion
  '13':
    recurring_customers: 800
    jobs_per_week: 4500
    monthly_revenue_eur: 2500000
    monthly_salaries_eur: 1700000
    gross_margin_eur: 800000        # 2500000 - 1700000
    gross_margin_pct: 32.0
    est_valuation_eur: 150000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CMO"
      - "CISO"
      - "CHRO"

  # Phase 14 ‚Äì Distributed Data
  '14':
    recurring_customers: 1200
    jobs_per_week: 6500
    monthly_revenue_eur: 4000000
    monthly_salaries_eur: 2800000
    gross_margin_eur: 1200000       # 4000000 - 2800000
    gross_margin_pct: 30.0
    est_valuation_eur: 240000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CMO"
      - "CISO"
      - "CHRO"

  # Phase 15 ‚Äì Service Mesh
  '15':
    recurring_customers: 1700
    jobs_per_week: 9000
    monthly_revenue_eur: 6000000
    monthly_salaries_eur: 4500000
    gross_margin_eur: 1500000       # 6000000 - 4500000
    gross_margin_pct: 25.0
    est_valuation_eur: 360000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CMO"
      - "CISO"
      - "CHRO"

  # Phase 16 ‚Äì Multi-Cloud Federation
  '16':
    recurring_customers: 2400
    jobs_per_week: 13000
    monthly_revenue_eur: 9000000
    monthly_salaries_eur: 7000000
    gross_margin_eur: 2000000       # 9000000 - 7000000
    gross_margin_pct: 22.2
    est_valuation_eur: 540000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CMO"
      - "CISO"
      - "CHRO"
      - "CIO"

  # Phase 17 ‚Äì Extreme Write Optimization
  '17':
    recurring_customers: 3200
    jobs_per_week: 18000
    monthly_revenue_eur: 13000000
    monthly_salaries_eur: 10000000
    gross_margin_eur: 3000000       # 13000000 - 10000000
    gross_margin_pct: 23.1
    est_valuation_eur: 800000000
    valuation_multiple_arr: 5.1
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CMO"
      - "CISO"
      - "CHRO"
      - "CIO"
      - "CRO"

  # Phase 18 ‚Äì Decentralized Nervous System
  '18':
    recurring_customers: 4500
    jobs_per_week: 25000
    monthly_revenue_eur: 20000000
    monthly_salaries_eur: 15000000
    gross_margin_eur: 5000000       # 20000000 - 15000000
    gross_margin_pct: 25.0
    est_valuation_eur: 1200000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CMO"
      - "CISO"
      - "CHRO"
      - "CIO"
      - "CRO"

  # Phase 19 ‚Äì The Metropolis / Planet-Scale AI
  '19':
    recurring_customers: 7000
    jobs_per_week: 35000
    monthly_revenue_eur: 35000000
    monthly_salaries_eur: 27000000
    gross_margin_eur: 8000000       # 35000000 - 27000000
    gross_margin_pct: 22.9
    est_valuation_eur: 2100000000
    valuation_multiple_arr: 5.0
    c_suite_roles:
      - "CEO"
      - "COO"
      - "CFO"
      - "CTO"
      - "CPO"
      - "CMO"
      - "CISO"
      - "CHRO"
      - "CIO"
      - "CRO"

phase_annotations:
  '1':
    label: "Phase 1 ‚Äì Prove the Model"
    business_kpis:
      - id: "kpi_ceo_time_in_ops_hours_per_week"
        description: "Hours per week the CEO spends on field ops or manual coordination."
        target: "<= 10"
      - id: "kpi_first_paying_customer"
        description: "At least one paying customer on the system."
        target: ">= 1"
    feature_toggles:
      enabled:
        - "core_engine.work_orders.basic"
      disabled:
        - "routing.osrm_advanced"
        - "kafka_event_bus"
        - "federated_learning"
    cost_guards:
      max_monthly_infra_eur: 1500
      max_regions: 1
      max_persistent_nodes: 1

  '5':
    label: "Phase 5 ‚Äì Optimize Routing"
    business_kpis:
      - id: "kpi_avg_travel_time_minutes"
        description: "Average travel time per job."
        target: "<= 25"
      - id: "kpi_routing_cost_per_job_eur"
        description: "All-in routing cost per completed job."
        target: "<= 5"
    feature_toggles:
      enabled:
        - "routing.osrm_advanced"
        - "dispatch.cost_based_routing"
      disabled:
        - "multi_region_anycast"
        - "federated_learning"
    cost_guards:
      max_monthly_infra_eur: 4000
      max_regions: 1

  '9':
    label: "Phase 9 ‚Äì Event-Driven Architecture"
    business_kpis:
      - id: "kpi_events_per_second"
        description: "Sustained event throughput on Kafka nervous system."
        target: ">= 100"
      - id: "kpi_sync_vs_async_ratio"
        description: "Share of operations served via events vs RPC."
        target: ">= 0.7"
    feature_toggles:
      enabled:
        - "kafka_event_bus"
        - "audit_logging"
        - "telemetry_firehose"
      disabled:
        - "multi_region_anycast"
    cost_guards:
      max_regions: 3
      max_kafka_clusters: 1
      notes: "Focus on a single cloud + single Kafka cluster with strong observability."

  '13':
    label: "Phase 13 ‚Äì Multi-Region Expansion"
    business_kpis:
      - id: "kpi_rpo_seconds"
        description: "Ledger RPO for committed transactions across regions."
        target: "0"
      - id: "kpi_cross_region_latency_p95_ms"
        description: "95th percentile latency for cross-region workflows."
        target: "<= 400"
    feature_toggles:
      enabled:
        - "multi_region_anycast"
        - "multi_region_k8s_federation"
        - "region_local_pii_enforcement"
      disabled:
        - "multi_cloud_federation"
    cost_guards:
      max_regions: 3
      max_monthly_infra_eur: 25000
      notes: "Add regions only after hitting utilization & revenue thresholds."

  '19':
    label: "Phase 19 ‚Äì The Metropolis / Planet-Scale AI"
    business_kpis:
      - id: "kpi_workers_managed"
        description: "Number of human workers + robots actively orchestrated."
        target: ">= 1000000"
      - id: "kpi_global_sla_attainment"
        description: "Fraction of jobs meeting SLA across all regions."
        target: ">= 0.99"
      - id: "kpi_region_outage_autonomy_hours"
        description: "Hours of safe autonomous operation during control-plane outage."
        target: ">= 24"
    feature_toggles:
      enabled:
        - "planet_scale_federated_learning"
        - "edge_autonomy"
        - "kafka_federation"
        - "global_model_governance"
        - "region_local_feature_stores"
      disabled: []
    cost_guards:
      notes: >
        Phase 19 optimizes cost via SRE runbooks and capacity planning per region
        instead of a hard global budget cap; cost is managed via SLOs and
        utilization targets rather than fixed t-shirt sizes.
      
data_models:
  - name: hr.employee
    storage_engine: CockroachDB
    partition_strategy: >
      REGIONAL BY ROW AS region (Locality=legal residency; Survival
      Goal=REGION_FAILURE).
    fields:
      - 'employee_id: UUID NOT NULL DEFAULT gen_random_uuid()'
      - 'region: crdb_internal_region NOT NULL'
      - >-
        employee_global_id: UUID NOT NULL  # Stable cross-region reference
        (non-PII)
      - 'org_id: UUID NOT NULL  # Tenant'
      - 'keycloak_user_id: STRING NOT NULL'
      - 'spiffe_id: STRING NOT NULL  # SPIRE SVID subject, per device/workload'
      - 'hacl_pubkey: BYTES NOT NULL  # Ed25519 public key bound to SPIFFE ID'
      - >-
        hacl_pubkey_fingerprint: STRING NOT NULL  # SHA-256 for non-PII global
        lookup
      - 'status: ENUM(''active'',''paused'',''terminated'') NOT NULL DEFAULT ''active'''
      - 'skill_tags: STRING[] NOT NULL DEFAULT ''{}'''
      - 'legal_residency_country: STRING(2) NOT NULL'
      - 'pii_full_name: STRING NOT NULL'
      - 'pii_email: STRING NOT NULL'
      - 'pii_phone: STRING NULL'
      - 'created_at: TIMESTAMPTZ NOT NULL DEFAULT now()'
      - 'updated_at: TIMESTAMPTZ NOT NULL DEFAULT now()'
      - PRIMARY KEY (region, employee_id)
      - UNIQUE INDEX hr_employee_global (employee_global_id)
      - UNIQUE INDEX hr_employee_spiffe (spiffe_id)
  - name: account.move
    storage_engine: CockroachDB
    partition_strategy: >
      REGIONAL BY ROW AS region (Geo-Partitioned; Survival Goal=REGION_FAILURE;
      target RPO=0).
    fields:
      - 'id: UUID NOT NULL DEFAULT gen_random_uuid()'
      - 'region: crdb_internal_region NOT NULL'
      - 'company_id: UUID NOT NULL'
      - 'journal_id: UUID NOT NULL'
      - 'period_id: UUID NOT NULL'
      - 'debit_account_id: UUID NOT NULL'
      - 'credit_account_id: UUID NOT NULL'
      - 'amount_micros: INT8 NOT NULL CHECK (amount_micros > 0)'
      - 'currency_code: STRING(3) NOT NULL'
      - 'author_spiffe_id: STRING NOT NULL'
      - 'author_employee_global_id: UUID NOT NULL'
      - 'hacl_signature: BYTES NOT NULL  # Non-repudiation'
      - 'reversal_of: UUID NULL'
      - >-
        state: ENUM('draft','pending','posted','voided') NOT NULL DEFAULT
        'draft'
      - 'posted_at: TIMESTAMPTZ NOT NULL DEFAULT now()'
      - PRIMARY KEY (region, id)
      - INDEX move_by_journal (region, journal_id, posted_at DESC)
      - >-
        UNIQUE INDEX global_move_hash (sha256(id::STRING || author_spiffe_id ||
        amount_micros::STRING))
  - name: work.order
    storage_engine: CockroachDB
    partition_strategy: >
      REGIONAL BY ROW AS region (Local scheduling + compliance; cross-region
      reads only on non-PII fields).
    fields:
      - 'order_id: UUID NOT NULL DEFAULT gen_random_uuid()'
      - 'region: crdb_internal_region NOT NULL'
      - 'org_id: UUID NOT NULL'
      - 'customer_global_id: UUID NOT NULL  # Non-PII reference'
      - 'site_h3_r12: INT8 NOT NULL  # Exact job microcell'
      - 'site_h3_r8: INT8 NOT NULL   # Macro density cell'
      - 'sla_window_start: TIMESTAMPTZ NOT NULL'
      - 'sla_window_end: TIMESTAMPTZ NOT NULL'
      - 'expected_minutes: INT4 NOT NULL'
      - 'priority: ENUM(''low'',''normal'',''high'',''urgent'') NOT NULL DEFAULT ''normal'''
      - >-
        state: ENUM('created','allocated','in_progress','completed','canceled')
        NOT NULL
      - >-
        allocated_employee_global_id: UUID NULL  # Set only via dispatch
        workflows
      - 'dispatch_workflow_id: STRING NOT NULL  # Temporal workflow ownership'
      - 'price_micros: INT8 NOT NULL'
      - 'currency_code: STRING(3) NOT NULL'
      - 'created_at: TIMESTAMPTZ NOT NULL DEFAULT now()'
      - 'updated_at: TIMESTAMPTZ NOT NULL DEFAULT now()'
      - PRIMARY KEY (region, order_id)
      - INDEX order_by_cell (region, site_h3_r8, sla_window_start)
      - INDEX order_state (region, state)
  - name: fleet.telemetry.raw
    storage_engine: ScyllaDB
    partition_strategy: >
      TWCS with 5-minute base window. partition_key = (region_hour, h3_r8,
      shard), clustering_key = (agent_id, event_ts DESC). shard = hash(agent_id)
      % N to keep <20k writes/sec/partition.
    fields:
      - 'region_hour: TEXT  # PARTITION KEY 1: ''{region}_{yyyyMMddHH}'''
      - 'h3_r8: BIGINT      # PARTITION KEY 2: macrocell locality'
      - 'shard: SMALLINT    # PARTITION KEY 3: dispersion'
      - 'agent_id: UUID     # CLUSTERING KEY 1'
      - 'event_ts: TIMESTAMP # CLUSTERING KEY 2 DESC'
      - 'h3_r12: BIGINT'
      - 'battery_v: FLOAT'
      - 'motion_state: TINYINT'
      - 'payload: BLOB  # Protobuf/Flatbuffers'
      - PRIMARY KEY ((region_hour, h3_r8, shard), agent_id, event_ts)
  - name: customer.account
    storage_engine: CockroachDB
    partition_strategy: >
      REGIONAL BY ROW AS region (Locality=customer residency; Survival
      Goal=REGION_FAILURE).
    fields:
      - 'customer_id: UUID NOT NULL DEFAULT gen_random_uuid()'
      - 'region: crdb_internal_region NOT NULL'
      - 'customer_global_id: UUID NOT NULL  # Non-PII directory key'
      - 'org_id: UUID NOT NULL'
      - 'billing_name: STRING NOT NULL'
      - 'billing_country: STRING(2) NOT NULL'
      - 'billing_city: STRING NOT NULL'
      - 'billing_postcode: STRING NOT NULL'
      - 'pii_primary_contact_name: STRING NOT NULL'
      - 'pii_primary_contact_email: STRING NOT NULL'
      - 'pii_primary_contact_phone: STRING NULL'
      - 'status: ENUM(''prospect'',''active'',''churned'') NOT NULL DEFAULT ''active'''
      - 'created_at: TIMESTAMPTZ NOT NULL DEFAULT now()'
      - 'updated_at: TIMESTAMPTZ NOT NULL DEFAULT now()'
      - PRIMARY KEY (region, customer_id)
      - UNIQUE INDEX customer_global (customer_global_id)
  - name: contract.subscription
    storage_engine: CockroachDB
    partition_strategy: >
      REGIONAL BY ROW AS region (Locality=customer residency; Survival
      Goal=REGION_FAILURE).
    fields:
      - 'subscription_id: UUID NOT NULL DEFAULT gen_random_uuid()'
      - 'region: crdb_internal_region NOT NULL'
      - 'customer_global_id: UUID NOT NULL'
      - 'plan_code: STRING NOT NULL'
      - 'billing_interval: ENUM(''weekly'',''biweekly'',''monthly'') NOT NULL'
      - 'price_micros: INT8 NOT NULL'
      - 'currency_code: STRING(3) NOT NULL'
      - 'next_renewal_at: TIMESTAMPTZ NOT NULL'
      - 'status: ENUM(''active'',''paused'',''canceled'') NOT NULL DEFAULT ''active'''
      - 'created_at: TIMESTAMPTZ NOT NULL DEFAULT now()'
      - 'updated_at: TIMESTAMPTZ NOT NULL DEFAULT now()'
      - PRIMARY KEY (region, subscription_id)
      - INDEX subscription_by_customer (region, customer_global_id, status)
  - name: audit.event
    storage_engine: CockroachDB
    partition_strategy: >
      REGIONAL BY ROW AS region (Locality=actor residency; Survival
      Goal=REGION_FAILURE).
    fields:
      - 'event_id: UUID NOT NULL DEFAULT gen_random_uuid()'
      - 'region: crdb_internal_region NOT NULL'
      - 'occurred_at: TIMESTAMPTZ NOT NULL DEFAULT now()'
      - 'actor_spiffe_id: STRING NOT NULL'
      - 'actor_employee_global_id: UUID NULL'
      - 'event_type: STRING NOT NULL'
      - 'resource_type: STRING NOT NULL'
      - 'resource_id: STRING NOT NULL'
      - 'metadata_json: JSONB NOT NULL'
      - 'pii_touched: BOOL NOT NULL DEFAULT false'
      - PRIMARY KEY (region, event_id)
      - INDEX audit_by_actor (region, actor_spiffe_id, occurred_at DESC)
governance:
  data_classes:
    - id: P0_LEDGER
      name: Financial Ledger
      description: Financial records required for statutory reporting and audits.
      retention: 7y
      residency: region-local
      tables:
        - account.move
    - id: P1_PII_EMPLOYEE
      name: Employee PII
      description: Direct identifiers for employees and workers.
      retention: duration_of_employment_plus_6y
      residency: region-local
      tables:
        - hr.employee
    - id: P1_PII_CUSTOMER
      name: Customer PII
      description: Direct identifiers for customers and their primary contacts.
      retention: contract_duration_plus_6y
      residency: region-local
      tables:
        - customer.account
        - contract.subscription
    - id: P2_OPERATIONAL_TRUTH
      name: Operational Truth
      description: Operational data needed for routing, dispatch and job history.
      retention: 5y
      residency: region-local
      tables:
        - work.order
    - id: P3_TELEMETRY
      name: Telemetry
      description: High-volume device and location telemetry for optimization.
      retention: 365d
      residency: region-local
      tables:
        - fleet.telemetry.raw
    - id: P2_AUDIT
      name: Audit Logs
      description: Security & compliance audit trail.
      retention: 10y
      residency: region-local
      tables:
        - audit.event
structure:
  - platform/backstage/app.yaml
  - platform/backstage/catalog-info.yaml
  - platform/backstage/domains/finance.yaml
  - platform/backstage/domains/fleet.yaml
  - platform/backstage/domains/ai.yaml
  - platform/backstage/domains/simulation.yaml
  - platform/backstage/templates/python-service/template.yaml
  - platform/backstage/templates/rust-edge-agent/template.yaml
  - platform/backstage/templates/temporal-worker/template.yaml
  - platform/terraform/global/
  - platform/terraform/regions/eu-west-1/
  - platform/terraform/regions/us-east-1/
  - platform/terraform/regions/ap-northeast-1/
  - platform/charts/linkerd/
  - platform/charts/keycloak/
  - platform/charts/spire/
  - platform/charts/cockroachdb/
  - platform/charts/scylladb/
  - platform/charts/kafka-federated/
  - platform/policy/opa/
  - platform/policy/cedar/
  - platform/policy/opa/cross_region_egress.rego
  - platform/policy/opa/pii_column_guard.rego
  - platform/policy/opa/ai_no_db_write.rego
  - infrastructure/k8s/federation/control-plane/
  - infrastructure/k8s/federation/clusters/eu-west-1/placement.yaml
  - infrastructure/k8s/federation/clusters/us-east-1/placement.yaml
  - infrastructure/k8s/federation/clusters/ap-northeast-1/placement.yaml
  - infrastructure/linkerd/policies/deny-cross-region-default.yaml
  - infrastructure/linkerd/policies/allow-global-aggregates.yaml
  - infrastructure/ingress/anycast-bgp/
  - infrastructure/spire/registrations/
  - infrastructure/keycloak/realm-export/
  - infrastructure/kafka/regions/eu-west-1/
  - infrastructure/kafka/regions/us-east-1/
  - infrastructure/kafka/regions/ap-northeast-1/
  - infrastructure/kafka/federation/allowlist-topics.yaml
  - infrastructure/kafka/federation/mirrormaker2/replication-policy.yaml
  - data/flink/jobs/telemetry-enrichment/
  - data/flink/jobs/telemetry-aggregation/
  - data/flink/jobs/ai-feature-store/
  - data/contracts/kafka/
  - infrastructure/temporal/namespaces/eu-west-1.yaml
  - infrastructure/temporal/namespaces/us-east-1.yaml
  - infrastructure/temporal/namespaces/ap-northeast-1.yaml
  - services/temporal-workers/finance/
  - services/temporal-workers/dispatch/
  - services/temporal-workers/simulation/
  - services/temporal-workers/ai-governance/
  - services/core-engine/
  - services/core-engine/finance-ledger/
  - services/core-engine/finance-ledger/shards/eu-west-1/
  - services/core-engine/finance-ledger/shards/us-east-1/
  - services/core-engine/dispatch/
  - services/core-engine/dispatch/shards/eu-west-1/
  - services/core-engine/dispatch/shards/us-east-1/
  - services/core-engine/work-orders/
  - services/core-engine/work-orders/shards/ap-northeast-1/
  - services/core-engine/hr-registry/
  - services/core-engine/hr-registry/shards/eu-west-1/
  - services/simulation-engine/
  - services/simulation-engine/agent/
  - services/simulation-engine/economy-loop/
  - services/simulation-engine/needs-loop/
  - services/simulation-engine/shards/eu-west-1/
  - services/simulation-engine/shards/us-east-1/
  - services/simulation-engine/edge-k3s/
  - services/simulation-engine/edge-sync/
  - services/ai-player/
  - services/ai-player/shards/eu-west-1/
  - services/ai-player/shards/us-east-1/
  - services/ai-player/shards/ap-northeast-1/
  - services/ai-governor/
  - services/ai-governor/workflows/global_model_update_saga.py
  - services/ai-governor/policies/quorum.yaml
  - database/migrations/cockroach/
  - database/migrations/scylla/
  - database/schema/h3/
  - database/schema/acl/
  - observability/prometheus/
  - observability/prometheus/slos/global-ledger.yaml
  - observability/prometheus/slos/telemetry-firehose.yaml
  - observability/prometheus/slos/kafka-federation.yaml
  - observability/prometheus/slos/federated-learning.yaml
  - observability/prometheus/slos/edge-autonomy.yaml
  - observability/grafana/dashboards/
  - observability/alertmanager/
  - runbooks/
  - devcontainers/
  - docs/architecture/
  - docs/compliance/
  - local/dev/bootstrap/
  - platform/secrets/vault/
  - platform/terraform/policies/
  - routing/osrm/
  - routing/valhalla/
  - messaging/mqtt-broker/
  - data/lakehouse/
  - data/model-registry/
  - infrastructure/scylla/retention/
  - infrastructure/network/nautobot/
  - services/monitoring/sentry/
  - services/erp/odoo-adapter/
  - services/ml/triton-inference/
  - services/calendar/cal-com-adapter/
  - services/api/public/
  - services/worker-app/mobile/
  - services/temporal-workers/compliance/

files:
  - path: services/simulation-engine/agent/behavior.rs
    description: >
      Edge hybrid agent brain. Utility arbitration between macro-demand
      incentives (OpenRCT2 DNA) and micro-need decay (FreeSO DNA). H3 Res12
      micro-cells for movement. Reads only local state; requests/accepts work
      exclusively via Temporal workflows.
    content: >
      use h3o::{CellIndex, Resolution};

      use std::time::{Duration, SystemTime};

      use uuid::Uuid;


       // ---------- Ports / Adapters (traits only; real impls live elsewhere) ----------


      pub trait TemporalClient {
          fn poll_regional_work_orders(
              &self,
              region: &str,
              here_r12: CellIndex,
          ) -> Option<WorkOrder>;

          /// order_id must map directly to work.order.order_id (UUID) in CockroachDB,
          /// and the accept is implemented as a Temporal workflow signal.
          fn accept_order_via_workflow(&self, order_id: Uuid) -> bool;
      }


      pub trait LocalDensityIndex {
          /// Refreshes the 5-minute rolling demand + congestion snapshot
          /// from region-local Flink/Kafka aggregates (per H3 R9 cell).
          fn refresh_5m_snapshot(&mut self, region: &str);

          /// Returns normalized demand for a given R9 cell (0..1).
          fn demand_density_r9(&self, cell_r9: CellIndex) -> f32;

          /// Returns congestion cost (0..1) for a given R9 cell, derived
          /// from ScyllaDB/Flink telemetry aggregates.
          fn congestion_cost_r9(&self, cell_r9: CellIndex) -> f32;
      }


      pub trait PathCostHeuristic {
          /// Uses region-local OSRM/Valhalla weights and historical telemetry
          /// to estimate the cost (minutes) for a path over the H3 graph.
          fn estimated_path_cost(
              &self,
              region: &str,
              from_r12: CellIndex,
              to_r12: CellIndex,
          ) -> f32;
      }


      pub trait TelemetryEmitter {
          fn emit_heartbeat(&self, agent_id: Uuid, s: &AgentState);
      }


      // ---------- Domain Models ----------

      #[derive(Clone, Debug)]

      pub struct AgentState {
          pub energy: f32,        // FreeSO motive: 0..1
          pub supplies: f32,      // FreeSO motive: 0..1
          pub battery: f32,       // Device health: 0..1
          pub location_r12: CellIndex,
          pub last_needs_tick: SystemTime,
          pub last_economy_tick: SystemTime,
      }


      #[derive(Clone, Debug)]

      pub struct WorkOrder {
          /// Directly corresponds to work.order.order_id (UUID).
          pub id: Uuid,
          pub target_r12: CellIndex,
          pub reward: f32,        // macro-economy incentive
          pub urgency: f32,       // 0..1 SLA pressure
          pub expected_minutes: f32,
      }


      #[derive(Clone, Debug)]

      pub enum Action {
          EmergencyRecharge,
          RestockSupplies,
          ExecuteOrder(WorkOrder),
          Roam(CellIndex),
          Idle,
      }


      pub struct UtilityWeights {
          pub w_income: f32,
          pub w_energy: f32,
          pub w_supplies: f32,
          pub w_effort: f32,
          pub w_urgency: f32,
          pub w_congestion: f32,
      }


      pub struct HybridAgent<
          T: TemporalClient,
          D: LocalDensityIndex,
          P: PathCostHeuristic,
          E: TelemetryEmitter,
      > {
          pub id: Uuid,
          pub region: String,
          pub state: AgentState,
          pub weights: UtilityWeights,
          temporal: T,
          density: D,
          path: P,
          emitter: E,
      }


      impl<T: TemporalClient, D: LocalDensityIndex, P: PathCostHeuristic, E:
      TelemetryEmitter>
          HybridAgent<T, D, P, E>
      {
          pub fn tick(&mut self) -> Action {
              self.needs_tick_1s();
              self.economy_tick_5m();
              self.emitter.emit_heartbeat(self.id, &self.state);

              // ---------- FreeSO Needs Gate ----------
              if self.state.battery < 0.12 || self.state.energy < 0.10 {
                  return Action::EmergencyRecharge;
              }
              if self.state.supplies < 0.15 {
                  return Action::RestockSupplies;
              }

              // ---------- Temporal Work Pull ----------
              if let Some(order) =
                  self.temporal
                      .poll_regional_work_orders(&self.region, self.state.location_r12)
              {
                  let action = self.arbitrate(order.clone());
                  if let Action::ExecuteOrder(ref o) = action {
                      if !self.temporal.accept_order_via_workflow(o.id) {
                          return Action::Idle;
                      }
                  }
                  return action;
              }

              // ---------- Roam to demand hotspots ----------
              Action::Roam(self.best_neighbor_by_density())
          }

          fn needs_tick_1s(&mut self) {
              let now = SystemTime::now();
              let dt =
                  now.duration_since(self.state.last_needs_tick).unwrap_or(Duration::from_secs(1));
              let secs = dt.as_secs_f32().max(1.0);

              self.state.energy = (self.state.energy - 0.002 * secs).clamp(0.0, 1.0);
              self.state.battery = (self.state.battery - 0.0008 * secs).clamp(0.0, 1.0);
              self.state.last_needs_tick = now;
          }

          fn economy_tick_5m(&mut self) {
              let now = SystemTime::now();
              let dt = now
                  .duration_since(self.state.last_economy_tick)
                  .unwrap_or(Duration::from_secs(300));

              if dt.as_secs() < 300 {
                  return;
              }

              // Refresh demand surface snapshot for this agent's region from
              // region-local aggregates (Flink -> Kafka -> in-memory index).
              self.density.refresh_5m_snapshot(&self.region);
              self.state.last_economy_tick = now;
          }

          fn arbitrate(&self, order: WorkOrder) -> Action {
              let r9_here = self.state.location_r12.parent(Resolution::Nine).unwrap();
              let r9_target = order.target_r12.parent(Resolution::Nine).unwrap();

              let path_cost = self.path.estimated_path_cost(
                  &self.region,
                  self.state.location_r12,
                  order.target_r12,
              );
              let congestion_penalty =
                  self.density.congestion_cost_r9(r9_target) * self.weights.w_congestion;

              let energy_penalty = (1.0 - self.state.energy) * self.weights.w_energy;
              let supply_penalty = (1.0 - self.state.supplies) * self.weights.w_supplies;

              let utility = (order.reward * self.weights.w_income)
                  - (path_cost * self.weights.w_effort)
                  - congestion_penalty
                  - energy_penalty
                  - supply_penalty
                  + (order.urgency * self.weights.w_urgency);

              if utility > 0.0 {
                  Action::ExecuteOrder(order)
              } else {
                  let r9_here_density = self.density.demand_density_r9(r9_here);
                  let r9_target_density = self.density.demand_density_r9(r9_target);
                  if r9_target_density > r9_here_density * 1.2 {
                      Action::Roam(order.target_r12)
                  } else {
                      Action::Idle
                  }
              }
          }

          fn best_neighbor_by_density(&self) -> CellIndex {
              let r9 = self.state.location_r12.parent(Resolution::Nine).unwrap();
              let mut best = r9;
              let mut best_score =
                  self.density.demand_density_r9(r9) - self.density.congestion_cost_r9(r9);

              for n in r9.grid_disk(2).unwrap() {
                  let s =
                      self.density.demand_density_r9(n) - self.density.congestion_cost_r9(n);
                  if s > best_score {
                      best = n;
                      best_score = s;
                  }
              }
              best.child(Resolution::Twelve).unwrap()
          }
      }
  - path: database/migrations/cockroach/001_ledger.sql
    description: >
      CockroachDB sovereign ledger + workforce + operational work orders.
      Geo-partitioned by region, survival goal REGION_FAILURE, append-only
      ledger via RBAC.
    content: >
      -- ------------------------------

      -- 1) Multi-Region Topology

      -- ------------------------------

      ALTER DATABASE metropolis PRIMARY REGION "eu-west-1";

      ALTER DATABASE metropolis ADD REGION "us-east-1";

      ALTER DATABASE metropolis ADD REGION "ap-northeast-1";

      ALTER DATABASE metropolis SET SURVIVAL GOAL = 'REGION_FAILURE';


      -- ------------------------------

      -- 2) Types

      -- ------------------------------

      CREATE TYPE entry_state AS ENUM ('draft','pending','posted','voided');

      CREATE TYPE employee_status AS ENUM ('active','paused','terminated');

      CREATE TYPE order_state AS ENUM
      ('created','allocated','in_progress','completed','canceled');

      CREATE TYPE order_priority AS ENUM ('low','normal','high','urgent');


      -- ------------------------------

      -- 3) Workforce Registry

      -- ------------------------------

      CREATE TABLE IF NOT EXISTS "hr.employee" (
          employee_id UUID NOT NULL DEFAULT gen_random_uuid(),
          region crdb_internal_region NOT NULL,
          employee_global_id UUID NOT NULL,
          org_id UUID NOT NULL,

          keycloak_user_id STRING NOT NULL,
          spiffe_id STRING NOT NULL,
          hacl_pubkey BYTES NOT NULL,
          hacl_pubkey_fingerprint STRING NOT NULL,

          status employee_status NOT NULL DEFAULT 'active',
          skill_tags STRING[] NOT NULL DEFAULT '{}',
          legal_residency_country STRING(2) NOT NULL,

          pii_full_name STRING NOT NULL,
          pii_email STRING NOT NULL,
          pii_phone STRING NULL,

          created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
          updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),

          PRIMARY KEY (region, employee_id),
          UNIQUE (employee_global_id),
          UNIQUE (spiffe_id)
      );

      ALTER TABLE "hr.employee" SET LOCALITY REGIONAL BY ROW AS region;


      -- ------------------------------

      -- 4) Ledger Table (append-only by RBAC)

      -- ------------------------------

      CREATE TABLE IF NOT EXISTS "account.move" (
          id UUID NOT NULL DEFAULT gen_random_uuid(),
          region crdb_internal_region NOT NULL,

          company_id UUID NOT NULL,
          journal_id UUID NOT NULL,
          period_id UUID NOT NULL,

          debit_account_id UUID NOT NULL,
          credit_account_id UUID NOT NULL,
          amount_micros INT8 NOT NULL CHECK (amount_micros > 0),
          currency_code STRING(3) NOT NULL,

          author_spiffe_id STRING NOT NULL,
          author_employee_global_id UUID NOT NULL,
          hacl_signature BYTES NOT NULL,

          reversal_of UUID NULL,
          state entry_state NOT NULL DEFAULT 'draft',
          posted_at TIMESTAMPTZ NOT NULL DEFAULT now(),

          PRIMARY KEY (region, id),
          CONSTRAINT debit_credit_distinct CHECK (debit_account_id != credit_account_id),
          CONSTRAINT author_fk FOREIGN KEY (author_employee_global_id)
              REFERENCES "hr.employee"(employee_global_id)
      );

      ALTER TABLE "account.move" SET LOCALITY REGIONAL BY ROW AS region;

      CREATE INDEX IF NOT EXISTS move_by_journal ON "account.move" (region,
      journal_id, posted_at DESC);

      CREATE UNIQUE INDEX IF NOT EXISTS global_move_hash
          ON "account.move" (sha256(id::STRING || author_spiffe_id || amount_micros::STRING));

      -- ------------------------------

      -- 5) Work Orders (Temporal-owned operational truth)

      -- ------------------------------

      CREATE TABLE IF NOT EXISTS "work.order" (
          order_id UUID NOT NULL DEFAULT gen_random_uuid(),
          region crdb_internal_region NOT NULL,
          org_id UUID NOT NULL,
          customer_global_id UUID NOT NULL,

          site_h3_r12 INT8 NOT NULL,
          site_h3_r8 INT8 NOT NULL,

          sla_window_start TIMESTAMPTZ NOT NULL,
          sla_window_end TIMESTAMPTZ NOT NULL,
          expected_minutes INT4 NOT NULL,
          priority order_priority NOT NULL DEFAULT 'normal',

          state order_state NOT NULL,
          allocated_employee_global_id UUID NULL,
          dispatch_workflow_id STRING NOT NULL,

          price_micros INT8 NOT NULL,
          currency_code STRING(3) NOT NULL,

          created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
          updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),

          PRIMARY KEY (region, order_id)
      );

      ALTER TABLE "work.order" SET LOCALITY REGIONAL BY ROW AS region;

      CREATE INDEX IF NOT EXISTS order_by_cell
          ON "work.order" (region, site_h3_r8, sla_window_start);
      CREATE INDEX IF NOT EXISTS order_state_idx
          ON "work.order" (region, state);

      -- ------------------------------

      -- 6) Enforcement (mechanical via RBAC + Temporal-only writers)

      -- ------------------------------

      CREATE ROLE IF NOT EXISTS temporal_finance_writer;

      CREATE ROLE IF NOT EXISTS temporal_dispatch_writer;

      CREATE ROLE IF NOT EXISTS readonly_services;


      -- Append-only ledger: only INSERT is allowed for Temporal finance
      workers.

      GRANT INSERT ON TABLE "account.move" TO temporal_finance_writer;

      -- No UPDATE/DELETE grants -> append-only enforced at DB layer.


      -- Dispatch workers can create and update work orders inside their region.

      GRANT INSERT, UPDATE ON TABLE "work.order" TO temporal_dispatch_writer;


      -- Read-only views for services that must not mutate state.

      CREATE VIEW IF NOT EXISTS "account.move_readonly" AS
          SELECT * FROM "account.move";

      GRANT SELECT ON TABLE "hr.employee",
                               "work.order",
                               "account.move_readonly"
          TO readonly_services;

      -- DB credentials for temporal_* roles are mounted ONLY into Temporal
      worker

      -- service accounts via Kubernetes ServiceAccount + SPIRE + Vault.

      -- AI trainers use a distinct ServiceAccount with no DB role; OPA/Linkerd

      -- policy enforces that they can only talk to Temporal and Kafka.
  - path: database/migrations/cockroach/002_customer_contract_audit.sql
    description: >
      CockroachDB migration for customer.account, contract.subscription, and
      audit.event tables, aligned with governance.data_classes and data_models.
    content: |
      -- 002_customer_contract_audit.sql
      -- Customer accounts, subscriptions, and audit trail.

      -- Types for customer and subscription status + billing interval.
      CREATE TYPE IF NOT EXISTS customer_status AS ENUM ('prospect','active','churned');
      CREATE TYPE IF NOT EXISTS subscription_status AS ENUM ('active','paused','canceled');
      CREATE TYPE IF NOT EXISTS billing_interval AS ENUM ('weekly','biweekly','monthly');

      -- ------------------------------
      -- customer.account
      -- ------------------------------
      CREATE TABLE IF NOT EXISTS "customer.account" (
          customer_id UUID NOT NULL DEFAULT gen_random_uuid(),
          region crdb_internal_region NOT NULL,
          customer_global_id UUID NOT NULL,
          org_id UUID NOT NULL,

          billing_name STRING NOT NULL,
          billing_country STRING(2) NOT NULL,
          billing_city STRING NOT NULL,
          billing_postcode STRING NOT NULL,

          pii_primary_contact_name STRING NOT NULL,
          pii_primary_contact_email STRING NOT NULL,
          pii_primary_contact_phone STRING NULL,

          status customer_status NOT NULL DEFAULT 'active',

          created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
          updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),

          PRIMARY KEY (region, customer_id),
          UNIQUE (customer_global_id)
      );

      ALTER TABLE "customer.account" SET LOCALITY REGIONAL BY ROW AS region;

      -- ------------------------------
      -- contract.subscription
      -- ------------------------------
      CREATE TABLE IF NOT EXISTS "contract.subscription" (
          subscription_id UUID NOT NULL DEFAULT gen_random_uuid(),
          region crdb_internal_region NOT NULL,
          customer_global_id UUID NOT NULL,

          plan_code STRING NOT NULL,
          billing_interval billing_interval NOT NULL,

          price_micros INT8 NOT NULL,
          currency_code STRING(3) NOT NULL,

          next_renewal_at TIMESTAMPTZ NOT NULL,
          status subscription_status NOT NULL DEFAULT 'active',

          created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
          updated_at TIMESTAMPTZ NOT NULL DEFAULT now(),

          PRIMARY KEY (region, subscription_id),
          INDEX subscription_by_customer (region, customer_global_id, status)
      );

      ALTER TABLE "contract.subscription" SET LOCALITY REGIONAL BY ROW AS region;

      -- ------------------------------
      -- audit.event
      -- ------------------------------
      CREATE TABLE IF NOT EXISTS "audit.event" (
          event_id UUID NOT NULL DEFAULT gen_random_uuid(),
          region crdb_internal_region NOT NULL,

          occurred_at TIMESTAMPTZ NOT NULL DEFAULT now(),
          actor_spiffe_id STRING NOT NULL,
          actor_employee_global_id UUID NULL,

          event_type STRING NOT NULL,
          resource_type STRING NOT NULL,
          resource_id STRING NOT NULL,

          metadata_json JSONB NOT NULL,
          pii_touched BOOL NOT NULL DEFAULT false,

          PRIMARY KEY (region, event_id),
          INDEX audit_by_actor (region, actor_spiffe_id, occurred_at DESC)
      );

      ALTER TABLE "audit.event" SET LOCALITY REGIONAL BY ROW AS region;

  - path: database/schema/acl/roles_and_mappings.yaml
    description: >
      Declarative mapping from Kubernetes ServiceAccounts and SPIFFE IDs to
      CockroachDB roles and OPA policies. This makes the zero-trust posture
      auditable and testable.
    content: |
      # DB Roles (mirror of SQL DDL)
      roles:
        - name: temporal_finance_writer
          description: "Temporal workers that append to account.move."
        - name: temporal_dispatch_writer
          description: "Temporal workers that own work.order state changes."
        - name: readonly_services
          description: "Services that can only read operational truth."
        - name: temporal_hr_writer
          description: "Temporal workers that manage hr.employee & customer.account."

      # Workload identities -> DB roles
      serviceaccounts:
        - namespace: "finance"
          name: "temporal-finance-worker"
          spiffe_id_prefix: "spiffe://metropolis.local/ns/finance/sa/temporal-finance-worker"
          db_roles:
            - "temporal_finance_writer"

        - namespace: "dispatch"
          name: "temporal-dispatch-worker"
          spiffe_id_prefix: "spiffe://metropolis.local/ns/dispatch/sa/temporal-dispatch-worker"
          db_roles:
            - "temporal_dispatch_writer"

        - namespace: "hr"
          name: "temporal-hr-worker"
          spiffe_id_prefix: "spiffe://metropolis.local/ns/hr/sa/temporal-hr-worker"
          db_roles:
            - "temporal_hr_writer"

        - namespace: "services"
          name: "api-gateway"
          spiffe_id_prefix: "spiffe://metropolis.local/ns/services/sa/api-gateway"
          db_roles:
            - "readonly_services"

      # OPA policy bundles attached per role for runtime enforcement.
      opa_bundles:
        - role: "readonly_services"
          policies:
            - "platform/policy/opa/pii_column_guard.rego"
        - role: "temporal_finance_writer"
          policies:
            - "platform/policy/opa/pii_column_guard.rego"
        - role: "temporal_hr_writer"
          policies:
            - "platform/policy/opa/pii_column_guard.rego"
        - role: "any"
          policies:
            - "platform/policy/opa/ai_no_db_write.rego"
            - "platform/policy/opa/cross_region_egress.rego"
  - path: services/ai-player/federated_gym.py
    description: >
      Regional Federated Learning Gym. Consumes Flink-enriched local features
      from regional Kafka, computes/quantizes deltas vs cached regional weights,
      signs deltas using HACL* bound to SPIRE SVID, and proposes updates only
      via Temporal GlobalModelUpdateSaga. Training data never leaves region.
    content: >
      import json

      import os

      import time

      from typing import Any, Dict, List, Tuple, Optional


      from aiokafka import AIOKafkaConsumer

      from temporalio.client import Client


      # Verified Crypto (HACL*) + SPIRE identity bindings

      from crypto_bindings import (
          hacl_sign_ed25519,
          hacl_verify_ed25519,
          load_spire_keypair,
          spiffe_subject,
          pubkey_fingerprint,
      )


      REGION = os.getenv("REGION", "eu-west-1")

      TEMPORAL_HOST = os.getenv("TEMPORAL_HOST", "temporal-frontend:7233")

      TEMPORAL_NAMESPACE = os.getenv("TEMPORAL_NAMESPACE", f"ai-{REGION}")


      # Local-only feature stream derived by Flink job:

      # data/flink/jobs/ai-feature-store/

      # Schema (guaranteed by Avro/Protobuf contract via data/contracts/kafka/):

      # {

      #   "event_ts": float,          # seconds since epoch

      #   "features": { ... },        # model-ready vector

      #   "label": float | int | null # optional supervised signal

      # }

      FEATURE_TOPIC = os.getenv("FEATURE_TOPIC", f"{REGION}.ai.features.v1")


      MODEL_CACHE_URI = os.getenv("MODEL_CACHE_URI")  # sovereign region-local storage

      BATCH_SIZE = int(os.getenv("BATCH_SIZE", "1024"))
      STALENESS_S = int(os.getenv("MAX_STALENESS_S", "300"))
      MAX_LOCAL_OUTLIER_Z = float(os.getenv("MAX_LOCAL_OUTLIER_Z", "3.0"))
      LEARNING_RATE = float(os.getenv("LEARNING_RATE", "0.001"))

      GLOBAL_MODEL_UPDATE_WORKFLOW = os.getenv(
          "GLOBAL_MODEL_UPDATE_WORKFLOW", "GlobalModelUpdateSaga"
      )

      GLOBAL_MODEL_UPDATE_TASK_QUEUE = os.getenv(
          "GLOBAL_MODEL_UPDATE_TASK_QUEUE", "ai-governance-global"
      )



      class FederatedGym:
          """
          Phase-19 Federated Gym Contract:
          - Training data NEVER leaves the region.
          - Only signed gradient/model deltas cross regions.
          - Actuation boundary is Temporal workflows (no direct DB clients).
          - Identity/crypto: SPIRE SVID-bound Ed25519 keys (HACL*).

          Kafka topic FEATURE_TOPIC is the output of the Flink ai-feature-store job,
          with schema enforced via data/contracts/kafka/.
          """

          def __init__(self) -> None:
              self.keys = load_spire_keypair()
              self.subject = spiffe_subject()
              self.pubkey_fp = pubkey_fingerprint(self.keys.public)

              self.consumer: Optional[AIOKafkaConsumer] = None
              self.batch: List[Dict[str, Any]] = []
              self.regional_model = self._load_regional_model(MODEL_CACHE_URI)
              self.temporal: Optional[Client] = None

          async def run(self) -> None:
              # Temporal client (async-safe, regional namespace)
              self.temporal = await Client.connect(
                  TEMPORAL_HOST,
                  namespace=TEMPORAL_NAMESPACE,
              )

              # Async Kafka consumer (no async/blocking mismatch)
              self.consumer = AIOKafkaConsumer(
                  FEATURE_TOPIC,
                  bootstrap_servers=os.getenv("KAFKA_BROKERS"),
                  group_id=f"ai-gym-{REGION}",
                  enable_auto_commit=False,
                  value_deserializer=lambda m: json.loads(m.decode("utf-8")),
              )
              await self.consumer.start()
              try:
                  async for msg in self.consumer:
                      feat = msg.value
                      # Flink guarantees event_ts is part of the contract.
                      if time.time() - float(feat["event_ts"]) > STALENESS_S:
                          continue

                      self.batch.append(feat)
                      if len(self.batch) >= BATCH_SIZE:
                          await self._process_batch()
                          await self.consumer.commit()
              finally:
                  await self.consumer.stop()

          async def _process_batch(self) -> None:
              gradients, sample_count, zscore_ok = self._compute_gradients(self.batch)
              self.batch = []

              if sample_count == 0:
                  return

              if not zscore_ok:
                  # Local anomaly guard: suspicious batches are dropped, never exported.
                  return

              payload = {
                  "region": REGION,
                  "trainer_spiffe_id": self.subject,
                  "trainer_pubkey_fp": self.pubkey_fp,
                  "sample_count": sample_count,
                  "gradient_delta": gradients,
                  "ts": time.time(),
              }
              payload_bytes = json.dumps(payload, sort_keys=True).encode("utf-8")

              signature = hacl_sign_ed25519(self.keys.private, payload_bytes)
              # Local verification as belt-and-suspenders
              assert hacl_verify_ed25519(self.keys.public, payload_bytes, signature)

              # Temporal is the ONLY global actuation boundary.
              assert self.temporal is not None
              await self.temporal.start_workflow(
                  GLOBAL_MODEL_UPDATE_WORKFLOW,
                  payload,
                  signature.hex(),
                  id=f"fl-{REGION}-{int(time.time())}",
                  task_queue=GLOBAL_MODEL_UPDATE_TASK_QUEUE,
                  execution_timeout=600,
                  retry_policy={"maximum_attempts": 5, "initial_interval": 5},
              )

          def _load_regional_model(self, uri: Optional[str]) -> Dict[str, float]:
              """
              Load sovereign region-local model weights.

              Default path (if MODEL_CACHE_URI is unset) is a region-specific
              filesystem or object-store mount, e.g.:
              /var/lib/metropolis/models/{REGION}/route_policy_v19.json
              """
              default_path = f"/var/lib/metropolis/models/{REGION}/route_policy_v19.json"
              path = uri or default_path
              try:
                  with open(path, "r", encoding="utf-8") as f:
                      data = json.load(f)
                  # Ensure numeric weights
                  return {k: float(v) for k, v in data.items()}
              except FileNotFoundError:
                  # Cold-start defaults; will be updated by global governor.
                  return {"w_route_efficiency": 1.0, "w_supply_risk": 1.0}

          def _compute_gradients(
              self, features: List[Dict[str, Any]]
          ) -> Tuple[Dict[str, float], int, bool]:
              """
              Minimal but concrete gradient + anomaly implementation:

              - Consume Flink-enforced schema: each record has "features" and optional "label".
              - Compute simple gradients vs cached regional model (linear predictor).
              - Quantize deltas via rounding to 6 decimals for bandwidth.
              - Compute mean loss z-score; reject if |z| > MAX_LOCAL_OUTLIER_Z.
              """
              if not features:
                  return {}, 0, True

              weight_keys = list(self.regional_model.keys())
              grad_accum = {k: 0.0 for k in weight_keys}

              sum_loss = 0.0
              sum_sq_loss = 0.0
              count = 0

              for rec in features:
                  feats = rec.get("features") or {}
                  label = rec.get("label")
                  if label is None:
                      # Unlabeled samples are ignored for supervised update.
                      continue

                  count += 1
                  # Simple linear model: pred = w¬∑x over known keys.
                  pred = 0.0
                  for k in weight_keys:
                      pred += float(self.regional_model.get(k, 0.0)) * float(
                          feats.get(k, 0.0)
                      )

                  loss = float(label) - pred
                  sum_loss += loss
                  sum_sq_loss += loss * loss

                  # Accumulate gradients dL/dw_k ‚âà loss * x_k
                  for k in weight_keys:
                      grad_accum[k] += loss * float(feats.get(k, 0.0))

              if count == 0:
                  return {k: 0.0 for k in weight_keys}, 0, True

              mean_loss = sum_loss / count
              var_loss = max((sum_sq_loss / count) - (mean_loss * mean_loss), 0.0)
              std_loss = var_loss ** 0.5

              zscore_ok = True
              if std_loss > 0.0:
                  z = abs(mean_loss) / std_loss
                  zscore_ok = z <= MAX_LOCAL_OUTLIER_Z

              gradients: Dict[str, float] = {}
              for k in weight_keys:
                  raw_grad = (grad_accum[k] / count) * LEARNING_RATE
                  gradients[k] = round(raw_grad, 6)  # simple quantization

              return gradients, count, zscore_ok
  - path: services/temporal-workers/dispatch/workflows/dispatch_saga.yaml
    description: >
      Canonical Dispatch Saga contract. Documents the only allowed state
      transitions for work.order and which Temporal activities own them. This is
      the human + machine-readable source of truth for dispatch.
    content: |
      workflow: "DispatchSaga"
      version: 1
      description: >
        Orchestrates the lifecycle of a single work.order from 'created'
        to 'allocated' to 'in_progress' to 'completed' or 'canceled'.

      inputs:
        - name: order_id
          type: uuid
        - name: org_id
          type: uuid
        - name: region
          type: crdb_internal_region

      invariants:
        - "Exactly one ACTIVE saga per (region, order_id)."
        - "state transitions must be monotonic along the allowed graph."
        - "allocated_employee_global_id can only be set by this workflow."
        - "ledger posting for this order must happen after completion."

      states:
        - name: created
          allowed_next: ["allocated", "canceled"]
        - name: allocated
          allowed_next: ["in_progress", "canceled"]
        - name: in_progress
          allowed_next: ["completed", "canceled"]
        - name: completed
          allowed_next: []
        - name: canceled
          allowed_next: []

      activities:
        - name: FindCandidateAgents
          queue: "dispatch-activities"
          timeout_s: 10
          retries:
            max_attempts: 3
            backoff_s: 2

        - name: SendOfferToAgent
          queue: "dispatch-activities"
          timeout_s: 30
          retries:
            max_attempts: 5
            backoff_s: 5

        - name: ConfirmAcceptance
          queue: "dispatch-activities"
          timeout_s: 60
          retries:
            max_attempts: 3
            backoff_s: 10

        - name: MarkOrderAllocated
          queue: "dispatch-activities"
          timeout_s: 5
          rbac_role: "temporal_dispatch_writer"
          writes:
            - table: "work.order"
              columns:
                - "state"
                - "allocated_employee_global_id"
                - "dispatch_workflow_id"

        - name: AwaitJobCompletionSignal
          queue: "dispatch-activities"
          timeout_s: 86400  # 24h
          signal: "JobCompleted"

        - name: MarkOrderCompleted
          queue: "dispatch-activities"
          timeout_s: 5
          rbac_role: "temporal_dispatch_writer"
          writes:
            - table: "work.order"
              columns:
                - "state"
                - "updated_at"

      error_handling:
        cancel_on:
          - "order hard-deleted"
          - "org suspended"
        compensation:
          - "If order reverted from 'allocated' -> 'canceled', emit JobCanceled event."
        alerts:
          - name: "dispatch_saga_stuck"
            condition: "runtime > 4h AND state in ['created','allocated','in_progress']"
            severity: "page"

          
  - path: services/temporal-workers/finance/workflows/billing_saga.yaml
    description: >
      BillingSaga owns the lifecycle from completed work.order to posted
      account.move entries and external invoicing. This is the canonical
      contract between dispatch, finance, and the ledger.
    content: |
      workflow: "BillingSaga"
      version: 1
      description: >
        Handles billing for a single work.order: rating, taxation,
        ledger posting and invoice emission.

      inputs:
        - name: order_id
          type: uuid
        - name: org_id
          type: uuid
        - name: region
          type: crdb_internal_region

      invariants:
        - "Exactly one BillingSaga per (region, order_id)."
        - "Ledger entries must be posted AFTER order state = 'completed'."
        - "BillingSaga is the ONLY workflow allowed to INSERT into account.move for this order."

      activities:
        - name: LoadOrderSnapshot
          queue: "finance-activities"
          timeout_s: 5

        - name: ComputeCharges
          queue: "finance-activities"
          timeout_s: 10

        - name: PostLedgerEntries
          queue: "finance-activities"
          timeout_s: 10
          rbac_role: "temporal_finance_writer"
          writes:
            - table: "account.move"
              columns:
                - "company_id"
                - "journal_id"
                - "debit_account_id"
                - "credit_account_id"
                - "amount_micros"
                - "currency_code"
                - "author_spiffe_id"
                - "author_employee_global_id"
                - "hacl_signature"
                - "state"

        - name: EmitInvoice
          queue: "finance-activities"
          timeout_s: 20

      error_handling:
        cancel_on:
          - "order hard-deleted"
          - "org suspended"
        alerts:
          - name: "billing_saga_failed"
            condition: "state != 'completed' AND runtime > 10m"
            severity: "page"
  - path: >-
      services/temporal-workers/ai-governance/workflows/global_model_update_saga.yaml
    description: >
      GlobalModelUpdateSaga coordinates aggregation of regional gradient deltas,
      quorum checks and rollout/canary of new global models.
    content: |
      workflow: "GlobalModelUpdateSaga"
      version: 1
      description: >
        Aggregates signed federated deltas from regions, applies governance
        policies, and rolls out new model weights under canary controls.

      inputs:
        - name: update_id
          type: string

      invariants:
        - "All deltas must be Ed25519-verified against trainer_pubkey_fp."
        - "Quorum of regions must agree before promoting a global model."
        - "Model rollout must support canary + rollback."

      activities:
        - name: CollectRegionalDeltas
          queue: "ai-governance-activities"
          timeout_s: 60

        - name: VerifySignaturesAndQuorum
          queue: "ai-governance-activities"
          timeout_s: 30

        - name: AggregateAndPersistModel
          queue: "ai-governance-activities"
          timeout_s: 60

        - name: RolloutCanary
          queue: "ai-governance-activities"
          timeout_s: 300

        - name: PromoteGlobalModel
          queue: "ai-governance-activities"
          timeout_s: 60

      error_handling:
        compensation:
          - "On canary failure, rollback to previous model and emit AIModelRollback event."
        alerts:
          - name: "global_model_update_failed"
            condition: "runtime > 15m OR terminal_state = 'failed'"
            severity: "page"
  - path: platform/policy/opa/cross_region_egress.rego
    description: >
      OPA policy enforced via Envoy/Linkerd-ext authz. Denies cross-region
      traffic by default. Allows only a small, explicit set of global services
      (aggregators, governance, control plane).
    content: |
      package metropolis.cross_region_egress

      default allow = false

      # Input contract (from Envoy ext_authz / Linkerd policy):
      # input.source.region   - region of calling workload
      # input.target.region   - region of destination workload
      # input.target.service  - logical service name (e.g. "global-aggregator")
      # input.request.method  - HTTP method if HTTP
      # input.request.path    - Path for additional scoping

      same_region {
        input.source.region == input.target.region
      }

      allowed_global_service {
        input.target.service == "global-aggregator"
      }

      allowed_global_service {
        input.target.service == "ai-governor"
        input.request.path == "/v1/global-model-updates"
      }

      # Allow if:
      # - traffic is same-region, OR
      # - destination is in the small global allow-list.
      allow {
        same_region
      }

      allow {
        not same_region
        allowed_global_service
      }
  - path: platform/policy/opa/pii_column_guard.rego
    description: >
      PII column guard for SQL access. Evaluated by a SQL proxy sidecar or
      gateway before forwarding queries to CockroachDB. Blocks PII access for
      non-PII roles and enforces region-local reads for PII.
    content: |
      package metropolis.pii_column_guard

      default allow = false

      # Input contract (simplified):
      # input.role           - DB role (e.g. "readonly_services")
      # input.region         - region of workload
      # input.query.tables   - list of referenced tables
      # input.query.columns  - map table -> list of referenced columns
      # input.query.type     - "SELECT" | "INSERT" | "UPDATE" | "DELETE"

      pii_columns = {
        "hr.employee": [
          "pii_full_name",
          "pii_email",
          "pii_phone"
        ],
        "customer.account": [
          "pii_primary_contact_name",
          "pii_primary_contact_email",
          "pii_primary_contact_phone"
        ]
      }


      # PII is never readable by generic readonly services.
      deny_pii_for_readonly {
        input.role == "readonly_services"
        some t
        t := input.query.tables[_]
        some c
        c := input.query.columns[t][_]
        pii_columns[t][_] == c
      }

      allow {
        input.query.type == "SELECT"
        not deny_pii_for_readonly
      }

      # Writes to PII columns are only allowed via Temporal-owned roles.
      allow {
        input.query.type == "UPDATE"
        input.role == "temporal_hr_writer"
      }

      allow {
        input.query.type == "INSERT"
        input.role == "temporal_hr_writer"
      }
  - path: platform/policy/opa/ai_no_db_write.rego
    description: >
      Hard deny any direct database writes from AI workloads. AI pods are
      labeled with `workload_type=ai` and may only communicate with
      Temporal/Kafka, never databases or admin APIs.
    content: >
        package metropolis.ai_no_db_write

        default allow = true

        # Input contract:
        #
        # input.workload.labels.workload_type  - e.g. "ai" | "service"
        # input.target.service                 - logical destination (e.g. "cockroachdb")
        # input.request.method                 - HTTP method, or pseudo "SQL" verb.
        # input.request.protocol               - "http" | "postgres" | "mysql" | ...

        is_ai {
          input.workload.labels.workload_type == "ai"
        }

        is_db {
          input.target.service == "cockroachdb"
        }

        # Deny any DB call (read or write) from AI workloads.
        # AI pods may only talk to Temporal, Kafka, and other non-DB services.
        deny {
          is_ai
          is_db
        }

        allow {
          not deny
        }
  - path: infrastructure/linkerd/policies/deny-cross-region-default.yaml
    description: >
      Linkerd policy that sets a default-deny posture for outbound traffic from
      Metropolis workloads. Same-region traffic is allowed; cross-region calls
      must go via explicitly whitelisted global services and are additionally
      checked by OPA cross_region_egress.rego.
    content: |
      # Namespace-level default policy: require authenticated mTLS and deny
      # outbound traffic unless explicitly authorized by Server/ServerAuthorization.
      #
      # NOTE: This is a reference config; adapt annotations and CRD versions
      # to the Linkerd release you actually run.
      ---
      apiVersion: v1
      kind: Namespace
      metadata:
        name: metropolis
        annotations:
          # Only authenticated mesh traffic may enter workloads in this ns.
          config.linkerd.io/default-inbound-policy: all-authenticated
          # Outbound is deny-by-default; allow rules live in
          # allow-global-aggregates.yaml and service-specific policy.
          config.linkerd.io/default-outbound-policy: deny

      # Catch-all Server for Metropolis workloads. Fine-grained Servers can be
      # added per service if needed; this one establishes the "lockdown" default.
      ---
      apiVersion: policy.linkerd.io/v1beta1
      kind: Server
      metadata:
        name: metropolis-services
        namespace: metropolis
      spec:
        podSelector:
          matchLabels:
            app.kubernetes.io/part-of: metropolis
        port: 0           # all ports on the proxy
        proxyProtocol: HTTP/1

      # Same-namespace (‚âà same-region within this cluster) traffic is allowed.
      # Cross-namespace / cross-region calls are denied unless a more specific
      # ServerAuthorization explicitly permits them.
      ---
      apiVersion: policy.linkerd.io/v1beta1
      kind: ServerAuthorization
      metadata:
        name: metropolis-same-namespace
        namespace: metropolis
      spec:
        server:
          name: metropolis-services
        client:
          meshTLS:
            serviceAccounts:
              - name: "*"
                namespace: metropolis

  - path: infrastructure/linkerd/policies/allow-global-aggregates.yaml
    description: >
      Linkerd policy that whitelists the small set of global control-plane
      services allowed to receive cross-region traffic (global-aggregator,
      ai-governor). Everything else remains region-local by default.
    content: |
      # Global aggregator: consumes anonymized aggregates + hashes.
      ---
      apiVersion: policy.linkerd.io/v1beta1
      kind: Server
      metadata:
        name: global-aggregator
        namespace: platform
      spec:
        podSelector:
          matchLabels:
            app: global-aggregator
        port: 8080
        proxyProtocol: HTTP/1

      ---
      apiVersion: policy.linkerd.io/v1beta1
      kind: ServerAuthorization
      metadata:
        name: allow-global-aggregator-from-metropolis
        namespace: platform
      spec:
        server:
          name: global-aggregator
        client:
          meshTLS:
            # Any Metropolis workload may send anonymized aggregates / hashes
            # to the global aggregator, subject to OPA cross_region_egress.rego.
            serviceAccounts:
              - name: "*"
                namespace: metropolis

      # AI governor: consumes signed federated-learning deltas only.
      ---
      apiVersion: policy.linkerd.io/v1beta1
      kind: Server
      metadata:
        name: ai-governor
        namespace: ai
      spec:
        podSelector:
          matchLabels:
            app: ai-governor
        port: 8080
        proxyProtocol: HTTP/1

      ---
      apiVersion: policy.linkerd.io/v1beta1
      kind: ServerAuthorization
      metadata:
        name: allow-ai-governor-from-metropolis
        namespace: ai
      spec:
        server:
          name: ai-governor
        client:
          meshTLS:
            serviceAccounts:
              - name: "*"
                namespace: metropolis

      
  - path: observability/prometheus/slos/global-ledger.yaml
    description: >
      SLO definitions for the global ledger (account.move). Encodes availability
      and freshness targets with alerting hints for Alertmanager.
    content: |
      service: "global-ledger"
      owner: "team-finance-platform"
      slos:
        - name: "ledger-availability"
          objective: 99.99
          period: 30d
          sli:
            events:
              total: >
                sum(rate(http_requests_total{
                  job="finance-ledger",
                  route="/v1/posting"
                }[5m]))
              bad: >
                sum(rate(http_requests_total{
                  job="finance-ledger",
                  route="/v1/posting",
                  code=~"5.."
                }[5m]))
          alerting:
            page:
              threshold_burn_rate: 14.4   # 2h / 30d
              window: 2h
            ticket:
              threshold_burn_rate: 2.0
              window: 24h

        - name: "ledger-freshness"
          objective: 99.9
          period: 30d
          sli:
            events:
              total: >
                sum(rate(cockroachdb_txn_commits_total{
                  cluster="metropolis"
                }[5m]))
              bad: >
                sum(rate(metropolis_ledger_lag_seconds_bucket{
                  le="300"
                }[5m])) == 0
          alerting:
            page:
              threshold_burn_rate: 6.0
              window: 4h
  - path: observability/prometheus/slos/telemetry-firehose.yaml
    description: >
      SLOs for the Scylla-backed telemetry firehose. Focused on write success
      and end-to-end delivery latency from edge agent to Scylla.
    content: |
      service: "telemetry-firehose"
      owner: "team-fleet-platform"
      slos:
        - name: "telemetry-write-success"
          objective: 99.95
          period: 30d
          sli:
            events:
              total: >
                sum(rate(metropolis_telemetry_ingest_attempts_total[5m]))
              bad: >
                sum(rate(metropolis_telemetry_ingest_errors_total[5m]))
          alerting:
            page:
              threshold_burn_rate: 14.4
              window: 2h

        - name: "telemetry-e2e-latency"
          objective: 99.9
          period: 30d
          sli:
            histogram:
              metric: "metropolis_telemetry_e2e_latency_seconds_bucket"
              le: "5"
          alerting:
            ticket:
              threshold_burn_rate: 4.0
              window: 24h
  - path: infrastructure/kafka/federation/allowlist-topics.yaml
    description: >
      Governance-aware allow-list of topics that may be replicated across
      regions by Kafka federation (MirrorMaker2). Only anonymized aggregates,
      hashes, and signed federated-learning deltas are permitted.
    content: |
      topics:
        - name: "ledger.account.move.hash.v1"
          data_class: "P0_LEDGER"
          description: "Region-level hashes/attestations for account.move; no raw entries."
        - name: "telemetry.aggregate.v1"
          data_class: "P3_TELEMETRY"
          description: "Aggregated, non-identifying telemetry statistics."
        - name: "ai.federated.delta.v1"
          data_class: "P2_OPERATIONAL_TRUTH"
          description: "Signed gradient/model-weight deltas from regional FederatedGym."
      invariants:
        - "No topic with raw PII is ever added to this list."
        - "Topics MUST map to governance.data_classes with residency=region-local."
        - "Replication uses IdentityReplicationPolicy (no renaming)."

  - path: infrastructure/kafka/federation/mirrormaker2/replication-policy.yaml
    description: >
      MirrorMaker2 replication policy wiring the allow-list into the Kafka
      federation layer. Ensures only approved topics replicate across regions
      and that topic names are preserved.
    content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: mirrormaker2-replication-policy
        namespace: kafka
        labels:
          app: kafka-federation
      data:
        replication.properties: |
          connector.class=org.apache.kafka.connect.mirror.MirrorSourceConnector
          # Identity policy: do not rewrite topic names.
          replication.policy.class=org.apache.kafka.connect.mirror.IdentityReplicationPolicy

          # Source / target clusters (examples; one ConfigMap per pair in practice).
          clusters=eu-west-1,us-east-1,ap-northeast-1
          source.cluster.alias=eu-west-1
          target.cluster.alias=us-east-1

          # Only topics on the governance allow-list are replicated.
          # In practice, a small sidecar or init container can render
          # infrastructure/kafka/federation/allowlist-topics.yaml into this list.
          topics=ledger.account.move.hash.v1,telemetry.aggregate.v1,ai.federated.delta.v1

          # Keep ACLs in sync for the replicated topics.
          sync.topic.acls.enabled=true

          # Refresh topics/groups frequently to pick up config changes.
          refresh.topics.interval.seconds=60
          refresh.groups.interval.seconds=60


  - path: observability/prometheus/slos/kafka-federation.yaml
    description: >
      SLOs for cross-cluster Kafka federation (MirrorMaker2). Ensures healthy
      replication between regional Kafka clusters.
    content: |
      service: "kafka-federation"
      owner: "team-platform-messaging"
      slos:
        - name: "federation-availability"
          objective: 99.9
          period: 30d
          sli:
            events:
              total: >
                sum(rate(kafka_mirrormaker2_records_lag_max[5m]))
              bad: >
                sum(rate(kafka_mirrormaker2_records_lag_max[5m]) > 1000)
          alerting:
            page:
              threshold_burn_rate: 14.4
              window: 2h

        - name: "replication-latency"
          objective: 99.9
          period: 30d
          sli:
            histogram:
              metric: "metropolis_kafka_replication_lag_seconds_bucket"
              le: "5"
  - path: observability/prometheus/slos/federated-learning.yaml
    description: >
      SLOs for the federated learning control plane: update success rate and
      staleness of global models.
    content: |
      service: "federated-learning"
      owner: "team-ai-governance"
      slos:
        - name: "global-model-update-success"
          objective: 99.0
          period: 30d
          sli:
            events:
              total: >
                sum(rate(metropolis_global_model_update_attempts_total[5m]))
              bad: >
                sum(rate(metropolis_global_model_update_failures_total[5m]))
          alerting:
            ticket:
              threshold_burn_rate: 4.0
              window: 24h

        - name: "model-staleness"
          objective: 99.5
          period: 30d
          sli:
            events:
              total: >
                sum(rate(metropolis_global_model_inferences_total[5m]))
              bad: >
                sum(rate(metropolis_global_model_age_seconds_bucket{le="86400"}[5m])) == 0
  - path: observability/prometheus/slos/edge-autonomy.yaml
    description: >
      SLOs for edge autonomy: ability for agents to continue operating despite
      control-plane outages.
    content: |
      service: "edge-autonomy"
      owner: "team-fleet-platform"
      slos:
        - name: "autonomous-operation-time"
          objective: 99.0
          period: 30d
          sli:
            events:
              total: >
                sum(rate(metropolis_edge_agent_heartbeat_total[5m]))
              bad: >
                sum(rate(metropolis_edge_agent_heartbeat_total{
                  control_plane_connected="false"
                }[5m]) == 0)
        - name: "edge-heartbeat-availability"
          objective: 99.95
          period: 30d
          sli:
            events:
              total: >
                sum(rate(metropolis_edge_agent_heartbeat_total[5m]))
              bad: >
                sum(rate(metropolis_edge_agent_heartbeat_errors_total[5m]))
  - path: runbooks/global-ledger-partition-loss.md
    description: >
      Human-readable incident response guide for loss of a CockroachDB region or
      partition affecting account.move writes.
    content: |
      # Runbook: Global Ledger Partition Loss

      Service: global-ledger (account.move)
      Severity: SEV-1 (possible financial inconsistency)

      ## 1. Detection

      This runbook is triggered by any of the following:
      - SLO burn alert: `ledger-availability` paging alert
      - Alert: `cockroachdb_cluster_unavailable_regions > 0`
      - On-call intuition: sustained errors on /v1/posting for > 5 minutes

      ## 2. Triage

      1. Confirm impact:
         - Check Grafana dashboard: "Finance / Ledger Global Health".
         - Verify if writes are failing globally or only for a region.
      2. Identify failing region(s):
         - Query metric: `cockroachdb_node_liveness_miss_count`.
         - Check `metropolis_region_rpo_status` panel.

      ## 3. Immediate Actions

      1. If a single region is affected:
         - Verify that SURVIVAL GOAL=REGION_FAILURE is configured.
         - Confirm that other regions still accept writes.
         - Announce in #incident-room: "Ledger impact confined to region X".

      2. If multiple regions are affected:
         - Page CockroachDB on-call (if managed) or infra-primary.
         - Temporarily rate-limit non-critical posting traffic via Envoy.

      ## 4. Recovery

      - Once CockroachDB cluster is healthy:
        1. Verify `account.move` consistency via built-in SCRUB.
        2. Compare cross-region hash (global_move_hash) with aggregator job output.
        3. If mismatches are detected:
           - Open follow-up SEV-2 for reconciliation.
           - Coordinate with CFO for external communication if necessary.

      ## 5. Post-Incident

      - Write postmortem in /docs/incidents/YYYY-MM-DD-ledger-partition-loss.md.
      - Update SLO/alerts if false positives or blind spots were discovered.
      - Review deployment / maintenance timeline for regression risks.
  - path: runbooks/kafka-federation-incident.md
    description: >
      Incident response guide for Kafka federation issues (MirrorMaker2 lag,
      replication failures, or cross-region topic unavailability).
    content: |
      # Runbook: Kafka Federation Incident

      Service: kafka-federation
      Severity: SEV-1 if critical topics impacted

      ## 1. Detection

      - SLO pages from kafka-federation SLOs.
      - High replication lag in Grafana dashboard "Messaging / Federation".
      - Alerts from MirrorMaker2 exporters.

      ## 2. Triage

      - Identify affected regions and topics.
      - Determine whether lag is increasing or stable.
      - Confirm whether producers/consumers are healthy in source regions.

      ## 3. Immediate Actions

      - If only non-critical topics are impacted, lower severity.
      - If critical topics (e.g. JobCreated, JobCompleted) are impacted:
        - Temporarily degrade cross-region features that depend on them.
        - Notify on-call leads in #incident-room.

      ## 4. Recovery

      - Restart or scale MirrorMaker2 workers if saturated.
      - Throttle or pause non-critical replication if bandwidth constrained.
      - Once lag recovers to below SLO thresholds, downgrade the incident.

      ## 5. Post-Incident

      - Capture root cause, contributing factors, and mitigations.
      - Update kafka-federation SLOs or capacity plans if needed.
  - path: runbooks/ai-model-rollback.md
    description: >
      Runbook for rolling back a misbehaving global model version and restoring
      the previous stable model.
    content: |
      # Runbook: AI Model Rollback

      Service: federated-learning / ai-governor
      Severity: SEV-1 if causing widespread operational degradation

      ## 1. Detection

      - SLO alerts from federated-learning (update failures, model staleness).
      - Sudden degradation in KPIs attributed to a new model version.
      - GlobalModelUpdateSaga failures in Temporal UI.

      ## 2. Immediate Actions

      - Identify the offending model version and impacted regions.
      - Trigger the "RollbackToPreviousModel" activity via ai-governor
        or CLI tooling.
      - Reduce or disable use of the new model in canary regions.

      ## 3. Verification

      - Confirm that affected services are now using the previous model.
      - Monitor KPIs and SLOs for at least one hour.

      ## 4. Post-Incident

      - Open a postmortem for model evaluation gaps.
      - Update GlobalModelUpdateSaga policies (quorum, offline evaluation).
      - Ensure that a replayable evaluation dataset exists per region.
  - path: ci/pipelines/metropolis.yaml
    description: >
      CI/CD pipeline for the Metropolis monorepo. Covers unit tests, integration
      tests, contract tests, security scans and policy checks before deploying
      to Kubernetes.
    content: |
      name: metropolis-ci

      on:
        push:
          branches: ["main"]
        pull_request:
          branches: ["main"]

      jobs:
        lint-and-unit:
          runs-on: ubuntu-latest
          steps:
            - uses: actions/checkout@v4

            - name: Set up Rust
              uses: actions-rs/toolchain@v1
              with:
                toolchain: stable

            - name: Set up Python
              uses: actions/setup-python@v5
              with:
                python-version: "3.11"

            - name: Install deps
              run: |
                pip install -r requirements.txt || true

            - name: Rust fmt + clippy
              run: |
                cargo fmt --all -- --check
                cargo clippy --all-targets --all-features -- -D warnings

            - name: Python lint + unit
              run: |
                python -m compileall .
                pytest -q

        contract-tests:
          runs-on: ubuntu-latest
          needs: ["lint-and-unit"]
          steps:
            - uses: actions/checkout@v4

            - name: Run Kafka schema compatibility tests
              run: |
                ./scripts/ci/check_kafka_contracts.sh data/contracts/kafka/

            - name: Run DB migration dry-run
              run: |
                ./scripts/ci/dry_run_migrations.sh database/migrations/cockroach/

        security-and-policy:
          runs-on: ubuntu-latest
          needs: ["contract-tests"]
          steps:
            - uses: actions/checkout@v4

            - name: Dependency vulnerability scan
              run: |
                ./scripts/ci/scan_dependencies.sh

            - name: OPA policy check
              run: |
                opa test platform/policy/opa/ -v

        build-and-deploy:
          runs-on: ubuntu-latest
          needs: ["security-and-policy"]
          if: github.ref == 'refs/heads/main'
          steps:
            - uses: actions/checkout@v4

            - name: Build container images
              run: |
                ./scripts/ci/build_images.sh

            - name: Push images
              run: |
                ./scripts/ci/push_images.sh

            - name: Apply Kubernetes manifests (staging)
              run: |
                ./scripts/ci/deploy_k8s.sh staging

            - name: Run smoke tests
              run: |
                ./scripts/ci/smoke_tests.sh staging

  - path: database/migrations/cockroach/010_retention_and_roles.sql
    description: >
      Additional CockroachDB migration to enforce data retention policies and
      create missing Temporal roles (e.g. temporal_hr_writer) in line with
      governance.data_classes.
    content: |
      -- 010_retention_and_roles.sql
      -- Data retention and RBAC alignment with governance.data_classes.

      -- Ensure HR writer role exists for PII updates via Temporal-only workflows.
      CREATE ROLE IF NOT EXISTS temporal_hr_writer;

      GRANT INSERT, UPDATE ON TABLE "hr.employee" TO temporal_hr_writer;

      -- Enforce retention via TTLs aligned with data_classes.
      -- P0_LEDGER (account.move) -> 7y
      ALTER TABLE IF EXISTS "account.move"
        SET (ttl_expiration_expression = posted_at + INTERVAL '7 years');
        
      -- P2_AUDIT (audit.event) -> 10y
      ALTER TABLE IF EXISTS "audit.event"
        SET (ttl_expiration_expression = occurred_at + INTERVAL '10 years');

      -- P1_PII_EMPLOYEE (hr.employee) ~6y after employment status change.
      -- Assumes status/metadata updates `updated_at` when employment ends.
      ALTER TABLE IF EXISTS "hr.employee"
        SET (ttl_expiration_expression = updated_at + INTERVAL '6 years');

       -- P2_OPERATIONAL_TRUTH (work.order) -> 5y
       ALTER TABLE IF EXISTS "work.order"
         SET (ttl_expiration_expression = created_at + INTERVAL '5 years');
       
       -- P1_PII_CUSTOMER (customer.account) ~6y after latest activity.
       ALTER TABLE IF EXISTS "customer.account"
         SET (ttl_expiration_expression = updated_at + INTERVAL '6 years');

       -- P1_PII_CUSTOMER / subscriptions (~6y after latest activity).
       ALTER TABLE IF EXISTS "contract.subscription"
         SET (ttl_expiration_expression = updated_at + INTERVAL '6 years');



  - path: infrastructure/scylla/retention/telemetry_ttl.cql
    description: >
      ScyllaDB schema fragment enforcing 365d TTL for fleet.telemetry.raw in line
      with governance P3_TELEMETRY.
    content: |
      -- TTL for high-volume telemetry; raw samples kept for 365 days.
      -- Physical table backing data_models.name = "fleet.telemetry.raw"
      ALTER TABLE fleet.telemetry_raw
      WITH default_time_to_live = 60 * 60 * 24 * 365;

  - path: services/temporal-workers/compliance/workflows/data_retention.yaml
    description: >
      Temporal workflow that periodically enforces data retention policies,
      coordinating CockroachDB TTL jobs and Scylla cleanup.
    content: |
      workflow: "DataRetentionEnforcer"
      version: 1
      description: >
        Periodically verifies that DB TTLs and archive jobs conform to
        governance.data_classes; emits audit events for any override.

      schedule:
        cron: "0 3 * * *"  # daily at 03:00 UTC

      activities:
        - name: VerifyCockroachTTL
          queue: "compliance-activities"
          timeout_s: 60

        - name: VerifyScyllaTTL
          queue: "compliance-activities"
          timeout_s: 60

        - name: TriggerArchiveJobs
          queue: "compliance-activities"
          timeout_s: 300

      alerts:
        - name: "retention_policy_violation"
          condition: "non_compliant_resources > 0"
          severity: "ticket"

  - path: routing/osrm/osrm_stack.yaml
    description: >
      OSRM-based routing stack for Phase 5+; provides travel time estimates and
      route selection for dispatch and simulation.
    content: |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: osrm-config
        namespace: routing
      data:
        profile: "car"
        region: "eu-west-1"

      ---
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: osrm-backend
        namespace: routing
      spec:
        replicas: 2
        selector:
          matchLabels:
            app: osrm-backend
        template:
          metadata:
            labels:
              app: osrm-backend
          spec:
            containers:
              - name: osrm
                image: osrm/osrm-backend:latest
                args:
                  - "routed"
                  - "--algorithm=MLD"
                ports:
                  - containerPort: 5000

  - path: messaging/mqtt-broker/config.yaml
    description: >
      MQTT broker config for edge devices where Kafka is too heavy; used in
      early/edge phases before full Kafka rollout.
    content: |
      broker:
        cluster_name: "metropolis-mqtt"
        listen_address: "0.0.0.0:1883"
        max_connections: 10000
      auth:
        mode: "mtls"
        spiffe_trust_domain: "spiffe://metropolis.local"
      bridges:
        - name: "telemetry-to-kafka"
          topic_prefix: "edge/"
          kafka_topic: "telemetry.edge.raw"
          enabled: true

  - path: data/lakehouse/layout.yaml
    description: >
      Lakehouse layout for analytics and offline ML. Ties business domains to
      bronze/silver/gold tables per region.
    content: |
      storage:
        provider: "s3"
        bucket_prefix: "metropolis-lakehouse"
      layers:
        bronze:
          description: "Raw ingested data in regional buckets."
        silver:
          description: "Cleaned, conformed datasets."
        gold:
          description: "Curated aggregates and feature tables."
      domains:
        - name: finance
          base_path: "finance/"
        - name: fleet
          base_path: "fleet/"
        - name: ai_features
          base_path: "ai/features/"

  - path: platform/charts/vector-db/values.yaml
    description: >
      Helm values for a regional vector database used by AI features and
      similarity search workloads.
    content: |
      global:
        region: "eu-west-1"
      resources:
        requests:
          cpu: "2"
          memory: "8Gi"
      persistence:
        enabled: true
        size: "500Gi"

  - path: services/monitoring/sentry/config.yaml
    description: >
      Sentry-style error monitoring configuration for app, worker, and admin
      surfaces.
    content: |
      dsn: "${SENTRY_DSN}"
      environment: "${ENVIRONMENT}"
      sample_rate:
        transactions: 0.1
        errors: 1.0
      tags:
        service_group: "metropolis"
        region: "${REGION}"

  - path: services/erp/odoo-adapter/service.yaml
    description: >
      Adapter service that syncs account.move postings into an external ERP
      (e.g. Odoo/ERPNext) once they are posted.
    content: |
      service:
        name: "erp-odoo-adapter"
        namespace: "finance"
      subscriptions:
        - topic: "ledger.account.move.posted.v1"
      erp:
        type: "odoo"
        base_url: "${ERP_ODOO_URL}"
        auth_method: "api_key"
      invariants:
        - "Only posted entries are exported."
        - "Export failures must not block ledger posting."

  - path: services/ml/triton-inference/deployment.yaml
    description: >
      Triton inference server deployment for serving high-throughput models in
      later phases.
    content: |
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: triton-inference
        namespace: ai
      spec:
        replicas: 3
        selector:
          matchLabels:
            app: triton-inference
        template:
          metadata:
            labels:
              app: triton-inference
          spec:
            containers:
              - name: triton
                image: nvcr.io/nvidia/tritonserver:23.03-py3
                args: ["tritonserver", "--model-repository=/models"]
                ports:
                  - containerPort: 8000

  - path: services/calendar/cal-com-adapter/service.yaml
    description: >
      Cal.com adapter that syncs work orders and worker availability into
      calendar primitives for high-touch customers.
    content: |
      service:
        name: "cal-com-adapter"
        namespace: "services"
      calendars:
        provider: "cal.com"
        base_url: "${CALCOM_URL}"
      sync:
        interval_seconds: 60
        sources:
          - "work.order"
          - "hr.employee"

  - path: data/model-registry/layout.yaml
    description: >
      Logical layout of the sovereign, region-local model registry used by
      federated_gym and ai-governor.
    content: |
      registry:
        default_root: "/var/lib/metropolis/models"
      regions:
        - id: "eu-west-1"
          path: "eu-west-1/"
        - id: "us-east-1"
          path: "us-east-1/"
        - id: "ap-northeast-1"
          path: "ap-northeast-1/"
      models:
        - name: "route_policy_v19"
          format: "json"
          owner: "team-ai-governance"
          tags:
            - "routing"
            - "phase-19"

  - path: services/ai-governor/evaluation/offline_eval.py
    description: >
      Offline evaluation harness for new global models before rollout via
      GlobalModelUpdateSaga.
    content: |
      import json
      from typing import Dict, Iterable

      def load_eval_dataset(path: str) -> Iterable[Dict]:
          with open(path, "r", encoding="utf-8") as f:
              for line in f:
                  yield json.loads(line)

      def evaluate_model(model_weights: Dict[str, float], samples: Iterable[Dict]) -> Dict:
          total_loss = 0.0
          count = 0
          for rec in samples:
              feats = rec.get("features") or {}
              label = rec.get("label")
              if label is None:
                  continue
              pred = sum(float(model_weights.get(k, 0.0)) * float(feats.get(k, 0.0))
                         for k in model_weights.keys())
              loss = float(label) - pred
              total_loss += loss * loss
              count += 1
          mse = total_loss / count if count else 0.0
          return {"samples": count, "mse": mse}

      if __name__ == "__main__":
          # Minimal CLI hook; real wiring is via ai-governor workflows.
          pass

  - path: services/core-engine/config/feature_flags.yaml
    description: >
      Central feature-flag definitions keyed by phase_id and overlay. This
      connects the business roadmap to rollout of specific capabilities.
    content: |
      phases:
        "1":
          overlay: "bootstrap"
          flags:
            routing.osrm_advanced: false
            kafka_event_bus: false
            federated_learning: false
        "5":
          overlay: "bootstrap"
          flags:
            routing.osrm_advanced: true
            kafka_event_bus: false
            federated_learning: false
        "9":
          overlay: "expansion"
          flags:
            routing.osrm_advanced: true
            kafka_event_bus: true
            federated_learning: false
        "13":
          overlay: "metropolis"
          flags:
            kafka_event_bus: true
            multi_region_anycast: true
        "19":
          overlay: "metropolis"
          flags:
            kafka_event_bus: true
            federated_learning: true
            edge_autonomy: true

  - path: observability/prometheus/slos/public-api.yaml
    description: >
      SLOs for the public API surface (customer-facing API gateway).
    content: |
      service: "public-api"
      owner: "team-api-platform"
      slos:
        - name: "availability"
          objective: 99.9
          period: 30d
          sli:
            events:
              total: >
                sum(rate(http_requests_total{
                  job="public-api-gateway",
                  route=~"/v1/.*"
                }[5m]))
              bad: >
                sum(rate(http_requests_total{
                  job="public-api-gateway",
                  route=~"/v1/.*",
                  code=~"5.."
                }[5m]))
        - name: "latency-p95"
          objective: 99.0
          period: 30d
          sli:
            histogram:
              metric: "http_request_duration_seconds_bucket"
              le: "0.5"

  - path: observability/prometheus/slos/worker-app.yaml
    description: >
      SLOs for the worker app API used by field workers/robots.
    content: |
      service: "worker-app"
      owner: "team-worker-experience"
      slos:
        - name: "worker-app-availability"
          objective: 99.9
          period: 30d
          sli:
            events:
              total: >
                sum(rate(http_requests_total{
                  job="worker-app-api"
                }[5m]))
              bad: >
                sum(rate(http_requests_total{
                  job="worker-app-api",
                  code=~"5.."
                }[5m]))

  - path: observability/prometheus/slos/auth.yaml
    description: >
      SLOs for authentication/Keycloak surface.
    content: |
      service: "auth"
      owner: "team-identity"
      slos:
        - name: "auth-success-rate"
          objective: 99.9
          period: 30d
          sli:
            events:
              total: >
                sum(rate(auth_requests_total[5m]))
              bad: >
                sum(rate(auth_requests_total{result="error"}[5m]))

  - path: observability/prometheus/slos/backstage-portal.yaml
    description: >
      SLOs for the internal Backstage developer portal.
    content: |
      service: "backstage-portal"
      owner: "team-developer-platform"
      slos:
        - name: "portal-availability"
          objective: 99.5
          period: 30d
          sli:
            events:
              total: >
                sum(rate(http_requests_total{
                  job="backstage",
                  route=~"/.*"
                }[5m]))
              bad: >
                sum(rate(http_requests_total{
                  job="backstage",
                  route=~"/.*",
                  code=~"5.."
                }[5m]))

  - path: runbooks/dispatch-outage.md
    description: >
      Runbook for dispatch service outage or high error rates.
    content: |
      # Runbook: Dispatch Outage

      Service: dispatch / work.order
      Severity: SEV-1 if job allocation is impacted

      ## 1. Detection

      - Alerts from worker-app error rate or dispatch API 5xx.
      - SLO burn on work.order allocation latency.

      ## 2. Triage

      - Check Temporal DispatchSaga backlog and failure rates.
      - Inspect work.order state distribution (created vs allocated vs in_progress).

      ## 3. Mitigation

      - Scale dispatch workers.
      - Fallback to manual allocation for critical customers.

      ## 4. Post-Incident

      - Analyze failed sagas and routing pressure.
      - Adjust capacity / feature flags (e.g. disable advanced routing if overloading).

  - path: runbooks/temporal-cluster-incident.md
    description: >
      Runbook for Temporal control-plane degradation or outage.
    content: |
      # Runbook: Temporal Cluster Incident

      Service: temporal-frontend / temporal-workers
      Severity: SEV-1 if workflows are stalled globally

      ## 1. Detection

      - Temporal UI shows high task queue latency.
      - SLO alerts for workflow latency.

      ## 2. Immediate Actions

      - Verify DB and persistence backends.
      - Scale Temporal frontends and workers.
      - Enable edge autonomy mode if control-plane unreachable.

  - path: runbooks/scylla-hotspotting.md
    description: >
      Runbook for Scylla hotspot partitions or runaway write amplification for
      telemetry.
    content: |
      # Runbook: Scylla Hotspotting

      Service: telemetry-firehose / fleet.telemetry.raw

      ## 1. Detection

      - High write latency on selected partitions.
      - Alert: "scylla_hot_partition" firing.

      ## 2. Mitigation

      - Verify shard hashing for agent_id.
      - Increase N in shard = hash(agent_id) % N.
      - Scale Scylla nodes or reduce batch size from agents.

  - path: runbooks/cross-region-outage.md
    description: >
      Runbook for multi-region network partition or cloud provider outage.
    content: |
      # Runbook: Cross-Region Outage

      Service: multi-region control-plane / kafka-federation / global-ledger

      ## 1. Detection

      - kafka-federation SLOs burning.
      - CockroachDB unavailable in >= 2 regions.

      ## 2. Mitigation

      - Prioritize region-local operation and edge autonomy.
      - Temporarily disable cross-region features (federated learning, cross-region views).

  - path: runbooks/security-incident.md
    description: >
      Runbook for suspected security incident or breach.
    content: |
      # Runbook: Security Incident

      Service: all
      Severity: SEV-0 / SEV-1

      ## 1. Detection

      - Alerts from SIEM.
      - Unusual auth patterns, PII access anomalies.

      ## 2. Immediate Actions

      - Contain: revoke compromised credentials, isolate suspect workloads.
      - Preserve evidence: snapshot logs, DB, and key artifacts.
      - Notify security on-call and legal/compliance if needed.

  - path: platform/terraform/policies/cost-guardrails.tf
    description: >
      Terraform-level cost guardrails and budgets aligned with phase_annotations
      cost_guards.
    content: |
      variable "phase_id" {
        type    = string
        default = "1"
      }

      locals {
        max_monthly_infra_eur = lookup(
          {
            "1"  = 1500
            "5"  = 4000
            "9"  = 10000
            "13" = 25000
          },
          var.phase_id,
          50000
        )
      }

      # Pseudocode: integrate with cloud billing alerts.
      # resource "cloud_budget" "metropolis" { ... }

  - path: platform/secrets/vault/policies/metropolis.hcl
    description: >
      Vault policy defining which ServiceAccounts can read which secrets, tying
      into SPIRE/ServiceAccount identities.
    content: |
      path "secret/data/metropolis/*" {
        capabilities = ["read", "list"]
      }

      path "secret/data/metropolis/finance/*" {
        capabilities = ["read"]
      }

      path "secret/data/metropolis/ai/*" {
        capabilities = ["read"]
      }

  - path: docs/compliance/dpia_template.md
    description: >
      DPIA (Data Protection Impact Assessment) template for new Metropolis
      features and regions.
    content: |
      # DPIA Template

      ## 1. Project / Feature

      - Name:
      - Owner:
      - Regions impacted:

      ## 2. Data Categories

      - P0_LEDGER / P1_PII / P2_OPERATIONAL / P3_TELEMETRY usage:

      ## 3. Risk Assessment

      - Risks:
      - Mitigations:

  - path: docs/architecture/README.md
    description: >
      High-level architecture index for Metropolis, including maps to phases
      and overlays.
    content: |
      # Metropolis Architecture

      - /docs/architecture/phase_migration_temporal.md
      - /docs/architecture/data-topology.md
      - /docs/architecture/ai-federated-learning.md
  - path: docs/architecture/data-topology.md
    description: >
      Detailed description of Metropolis data topology: regions, engines,
      partitioning, and governance classes P0‚ÄìP3.
    content: |
      # Data Topology

      Metropolis separates data concerns along two primary axes:

      - **Region**: EU, US, and APAC regions, with SURVIVAL GOAL=REGION_FAILURE.
      - **Data Class**: P0_LEDGER, P1_PII, P2_OPERATIONAL_TRUTH, P3_TELEMETRY, P2_AUDIT.

      ## 1. Storage Engines

      - **CockroachDB**
        - Tables: `hr.employee`, `customer.account`, `contract.subscription`,
          `work.order`, `account.move`, `audit.event`
        - Locality: `REGIONAL BY ROW AS region`
        - Goal: strong consistency, 0-RPO ledger, region-local PII.

      - **ScyllaDB**
        - Tables: `fleet.telemetry.raw` (keyspace/table: `fleet.telemetry_raw`)
        - Goal: high write throughput for telemetry firehose with 365d TTL.

      - **Lakehouse**
        - Layout: `data/lakehouse/layout.yaml`
        - Layers: bronze/silver/gold per domain (`finance`, `fleet`, `ai_features`)
        - Goal: analytics & offline ML, with buckets partitioned by region.

      ## 2. Governance Classes

      - **P0_LEDGER** (`account.move`)
        - Retention: 7 years (TTL on `posted_at`).
        - Residency: region-local; cross-region via hashes/aggregates only.

      - **P1_PII_EMPLOYEE** (`hr.employee`)
      - **P1_PII_CUSTOMER** (`customer.account`)
        - Retention: duration of relationship + 6 years.
        - Residency: region-local; guarded by `pii_column_guard.rego` and
          Temporal-only writer roles.

      - **P2_OPERATIONAL_TRUTH** (`work.order`)
        - Retention: 5 years (TTL on `created_at`).
        - Residency: region-local; cross-region reads allowed on non-PII only.

      - **P3_TELEMETRY** (`fleet.telemetry.raw`)
        - Retention: 365 days via Scylla default TTL.
        - Residency: region-local; aggregated into Kafka + lakehouse for ML.

      - **P2_AUDIT** (`audit.event`)
        - Retention: 10 years (TTL on `occurred_at`).
        - Residency: region-local; used for DPIA, incident response, and for
          verifying policy enforcement.

      ## 3. Cross-Region Flows

      Cross-region flows follow the phase-level constraints:

      - Only **anonymized aggregates**, **signed gradient/weight deltas**, and
        **global hashes/attestations** may leave a region.
      - Enforced by:
        - Network policy + Linkerd (`deny-cross-region-default`, allow-list).
        - OPA (`cross_region_egress.rego` and `ai_no_db_write.rego`).
        - CockroachDB locality + RBAC (Temporal-owned writers only).

      ## 4. DPIA and Compliance

      New regions and features must:

      - Classify tables into P0‚ÄìP3.
      - Update retention settings (Cockroach TTL, Scylla TTL, archive workflows).
      - Complete a DPIA using `docs/compliance/dpia_template.md`.

  - path: docs/architecture/ai-federated-learning.md
    description: >
      Architecture of the federated learning system: regional gyms, global
      governor, Temporal sagas, and enforcement of sovereign data.
    content: |
      # AI Federated Learning

      Metropolis uses a **federated learning** pattern to keep raw training data
      region-local while still converging on high-quality global models.

      ## 1. Regional Federated Gyms

      Implemented in `services/ai-player/federated_gym.py`:

      - Consume region-local features from Kafka topic:
        - `${REGION}.ai.features.v1` produced by Flink jobs under
          `data/flink/jobs/ai-feature-store/`.
      - Load regional model weights from the sovereign model registry:
        - `data/model-registry/layout.yaml`
      - Compute gradients vs cached regional weights.
      - Run anomaly detection (z-score guard) to drop suspicious batches.
      - Sign gradient deltas with HACL* Ed25519 keys bound to SPIRE SVIDs.
      - Start `GlobalModelUpdateSaga` via Temporal; they **never** write to DB.

      ## 2. Global Model Governor

      Implemented by:

      - Workflow spec:
        - `services/temporal-workers/ai-governance/workflows/global_model_update_saga.yaml`
      - Orchestrates:
        - Collection of regional deltas.
        - Signature verification and quorum checks.
        - Aggregation and persistence of new global weights.
        - Canary rollout and rollback.

      All global updates are driven by Temporal sagas, providing:

      - Strong auditability.
      - Clear invariants around quorum, rollbacks, and per-region rollout.

      ## 3. Enforcement & Zero-Trust

      Federated learning is constrained by:

      - **Network policy**
        - Linkerd policies + `cross_region_egress.rego` allow only
          small set of global services (`global-aggregator`, `ai-governor`).
      - **DB access control**
        - `ai_no_db_write.rego` denies any call (read or write) to CockroachDB
          from workloads labeled `workload_type=ai`.
        - AI pods may only talk to Temporal, Kafka, and other non-DB services.
      - **RBAC**
        - Only Temporal worker roles (`temporal_finance_writer`,
          `temporal_dispatch_writer`, `temporal_hr_writer`) can mutate
          operational tables.

      ## 4. SLOs and Runbooks

      SLOs:

      - `observability/prometheus/slos/federated-learning.yaml`
        - Global model update success and staleness.
      - `observability/prometheus/slos/edge-autonomy.yaml`
        - Ensures regions and agents remain safe even if control plane or
          federated learning are degraded.

      Runbooks:

      - `runbooks/ai-model-rollback.md` for reverting misbehaving models.
      - `runbooks/cross-region-outage.md` for network/region failures.

      Together, these ensure that:

      - Training data never leaves its region.
      - Global models evolve under strict governance.
      - Failures in AI do not compromise safety, ledger integrity, or
        regulatory guarantees.

  - path: docs/architecture/phase_migration_temporal.md
    description: >
      Document describing how the system progresses from pre-Temporal phases to
      Temporal-owned actuation.
    content: |
      # Phase Migration: Temporal

      Phases 1‚Äì5:
      - No Temporal, simple cron/jobs and direct DB writes.

      Phase 6:
      - Introduce Temporal for critical workflows (dispatch, finance).

      Phases 7+:
      - All state transitions move under Temporal workflows.
      - Direct DB writes from services are deprecated and removed.

  - path: local/dev/bootstrap/docker-compose.bootstrap.yaml
    description: >
      Minimal single-region docker-compose stack for Phases 1‚Äì3 without
      Kubernetes or Kafka.
    content: |
      version: "3.9"
      services:
        db:
          image: postgres:16
          environment:
            POSTGRES_DB: metropolis
          ports:
            - "5432:5432"
        api:
          build: ../../services/core-engine
          environment:
            DATABASE_URL: "postgres://postgres@db/metropolis"
          ports:
            - "8080:8080"

  - path: .devcontainer/devcontainer.json
    description: >
      Devcontainer definition to give developers a reproducible local env with
      CockroachDB, Kafka, and tooling.
    content: |
      {
        "name": "Metropolis Dev",
        "image": "mcr.microsoft.com/devcontainers/base:ubuntu",
        "postCreateCommand": "scripts/dev/start_local_stack.sh",
        "customizations": {
          "vscode": {
            "extensions": [
              "ms-python.python",
              "rust-lang.rust-analyzer",
              "redhat.vscode-yaml"
            ]
          }
        }
      }

  - path: scripts/dev/start_local_stack.sh
    description: >
      Helper script to boot a trimmed local stack (DB, Temporal, Kafka) for
      developer workflows.
    content: |
      #!/usr/bin/env bash
      set -euo pipefail

      echo "Starting local Metropolis stack..."
      docker compose -f local/dev/bootstrap/docker-compose.bootstrap.yaml up -d

  - path: services/api/public/openapi.yaml
    description: >
      Public API surface definition tying business KPIs and SLOs to concrete
      routes.
    content: |
      openapi: "3.0.0"
      info:
        title: "Metropolis Public API"
        version: "1.0.0"
      paths:
        /v1/work-orders:
          get:
            summary: "List work orders"
          post:
            summary: "Create work order"

  - path: services/worker-app/mobile/app-config.yaml
    description: >
      Worker mobile app configuration with feature flags per phase.
    content: |
      phases:
        "1":
          features:
            metrics_dashboard: false
            live_routing: false
        "5":
          features:
            live_routing: true
        "9":
          features:
            live_routing: true
            offline_mode: true

